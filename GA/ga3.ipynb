{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Dense, Flatten, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from IPython.display import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Finetune_ResNet50():\n",
    "    def __init__(self, input_shape):\n",
    "\n",
    "        self.fitness = 0\n",
    "        # self.loss = 1000\n",
    "        \n",
    "        IMG_SHAPE = input_shape + (3,)\n",
    "        self.base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "        sample_arr = [True, False]\n",
    "        self.bool_arr = np.random.choice(sample_arr, size=len(self.base_model.layers))\n",
    "        self.update_trainable()\n",
    "        # self.base_model.trainable = True\n",
    "        # for idx, i in enumerate(self.base_model.layers):\n",
    "        #     i.trainable = self.bool_arr[idx]\n",
    "    \n",
    "    def update_trainable(self, bool_arr=None):\n",
    "        if bool_arr is not None: \n",
    "            self.bool_arr = bool_arr\n",
    "        self.base_model.trainable = True\n",
    "        for idx, i in enumerate(self.base_model.layers):\n",
    "            i.trainable = self.bool_arr[idx]\n",
    "        \n",
    "    def forward(self, learning_rate=0.001):\n",
    "        inputs = Input((28, 28, 1))\n",
    "        resized_x = tf.keras.layers.experimental.preprocessing.Resizing(32, 32)(inputs)\n",
    "        first_conv_layer = Conv2D(3, 1, padding='same', activation=None)(resized_x)\n",
    "\n",
    "        x = self.base_model(first_conv_layer, training = False)\n",
    "        x = Flatten()(x)\n",
    "        outputs = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs, name=\"fashion_mnist_resnet50_model\")\n",
    "\n",
    "        # 'categorical_crossentropy'은 y[0]=[0, 0, 0, 0, 0, 0, 0, 0, 1], y[1, 0, 0, 0, 0, 0, 0, 0, 0]과 같이 one-hot-encoding label일 경우에 사용\n",
    "        model.compile(loss=\"categorical_crossentropy\", \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate= learning_rate), \n",
    "        metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, model, train_data, train_targets, validation_data=(x_test, y_test), epochs=20, batch_size=256):\n",
    "    \n",
    "        early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        checkpoint_best_path = 'model_checkpoints_best/checkpoint'\n",
    "        checkpoint_best = ModelCheckpoint(filepath=checkpoint_best_path,\n",
    "                                        save_weights_only=True,\n",
    "                                        save_freq='epoch',\n",
    "                                        monitor='val_accuracy',\n",
    "                                        save_best_only=True,\n",
    "                                        verbose=1)\n",
    "        history = model.fit(train_data, train_targets,\n",
    "                        validation_data = validation_data,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        verbose = 1,\n",
    "                        callbacks=[early])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POPULATION = 10\n",
    "N_BEST = 6\n",
    "N_CHILDREN = 5\n",
    "PROB_MUTATION = 0.04\n",
    "\n",
    "epoch = 3\n",
    "batch_size =256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [Random_Finetune_ResNet50((32,32)) for _ in range(N_POPULATION)]\n",
    "best_genomes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(genomes[0].bool_arr ==genomes[1].bool_arr).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 23s 77ms/step - loss: 1.2382 - accuracy: 0.5092 - val_loss: 0.8256 - val_accuracy: 0.6602\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.7298 - accuracy: 0.7161 - val_loss: 0.8094 - val_accuracy: 0.6948\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.6146 - accuracy: 0.7604 - val_loss: 0.5666 - val_accuracy: 0.7838\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.5563 - accuracy: 0.7853 - val_loss: 0.5439 - val_accuracy: 0.7909\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.5075 - accuracy: 0.8051 - val_loss: 0.4931 - val_accuracy: 0.8101\n",
      "[0.6601999998092651, 0.6948000192642212, 0.7838000059127808, 0.7908999919891357, 0.8101000189781189]\n",
      "[0.8101000189781189, 0.7908999919891357, 0.7838000059127808, 0.6948000192642212, 0.6601999998092651]\n",
      "0.8101000189781189\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "\n",
    "genome = genomes[0]\n",
    "model = genome.forward(0.0001)\n",
    "history = genome.train_model(model, x_train, y_train, (x_test, y_test), epoch, 256)\n",
    "fitness = history.history['val_accuracy']\n",
    "\n",
    "print(fitness)\n",
    "sorted_fitness = sorted(fitness, reverse=True)\n",
    "print(sorted_fitness)\n",
    "\n",
    "genome.fitness = sorted_fitness[0]\n",
    "\n",
    "print(genomes[0].fitness)\n",
    "print(genomes[1].fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 75ms/step - loss: 1.8918 - accuracy: 0.2786 - val_loss: 1.4173 - val_accuracy: 0.4417\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 17s 71ms/step - loss: 0.8749 - accuracy: 0.6588 - val_loss: 0.6316 - val_accuracy: 0.7602\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 17s 71ms/step - loss: 0.6389 - accuracy: 0.7559 - val_loss: 0.5325 - val_accuracy: 0.7918\n",
      "Generation #1, Genome #0, Fitness: [0.4417000114917755, 0.760200023651123, 0.7918000221252441], Best Fitness: 0.7918000221252441\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 73ms/step - loss: 1.4972 - accuracy: 0.4287 - val_loss: 0.8490 - val_accuracy: 0.6632\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.7276 - accuracy: 0.7147 - val_loss: 0.7533 - val_accuracy: 0.7016\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.6388 - accuracy: 0.7505 - val_loss: 0.5933 - val_accuracy: 0.7718\n",
      "Generation #1, Genome #1, Fitness: [0.6632000207901001, 0.7016000151634216, 0.7717999815940857], Best Fitness: 0.7717999815940857\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 24s 75ms/step - loss: 1.5637 - accuracy: 0.3880 - val_loss: 0.9594 - val_accuracy: 0.6081\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.7814 - accuracy: 0.6963 - val_loss: 0.7552 - val_accuracy: 0.7127\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.6475 - accuracy: 0.7523 - val_loss: 0.6485 - val_accuracy: 0.7487\n",
      "Generation #1, Genome #2, Fitness: [0.6080999970436096, 0.7127000093460083, 0.7487000226974487], Best Fitness: 0.7487000226974487\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 73ms/step - loss: 1.9195 - accuracy: 0.2700 - val_loss: 1.0922 - val_accuracy: 0.5714\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.9256 - accuracy: 0.6352 - val_loss: 0.7843 - val_accuracy: 0.7120\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.6625 - accuracy: 0.7479 - val_loss: 0.6139 - val_accuracy: 0.7742\n",
      "Generation #1, Genome #3, Fitness: [0.571399986743927, 0.7120000123977661, 0.7742000222206116], Best Fitness: 0.7742000222206116\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 24s 73ms/step - loss: 2.1536 - accuracy: 0.1838 - val_loss: 1.3877 - val_accuracy: 0.4903\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 1.0558 - accuracy: 0.5793 - val_loss: 0.8186 - val_accuracy: 0.6809\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.7329 - accuracy: 0.7191 - val_loss: 0.7563 - val_accuracy: 0.7182\n",
      "Generation #1, Genome #4, Fitness: [0.4902999997138977, 0.680899977684021, 0.7182000279426575], Best Fitness: 0.7182000279426575\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 73ms/step - loss: 1.2401 - accuracy: 0.5296 - val_loss: 0.9450 - val_accuracy: 0.6521\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.6778 - accuracy: 0.7380 - val_loss: 0.7801 - val_accuracy: 0.6992\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5653 - accuracy: 0.7831 - val_loss: 0.5762 - val_accuracy: 0.7772\n",
      "Generation #1, Genome #5, Fitness: [0.6521000266075134, 0.6991999745368958, 0.7771999835968018], Best Fitness: 0.7771999835968018\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 72ms/step - loss: 1.9185 - accuracy: 0.2767 - val_loss: 1.2462 - val_accuracy: 0.4998\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.8834 - accuracy: 0.6544 - val_loss: 0.9154 - val_accuracy: 0.6591\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.7364 - accuracy: 0.7154 - val_loss: 0.6868 - val_accuracy: 0.7354\n",
      "Generation #1, Genome #6, Fitness: [0.4997999966144562, 0.6590999960899353, 0.7354000210762024], Best Fitness: 0.7354000210762024\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 25s 76ms/step - loss: 1.4539 - accuracy: 0.4390 - val_loss: 1.1024 - val_accuracy: 0.5469\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 17s 70ms/step - loss: 0.6827 - accuracy: 0.7402 - val_loss: 0.6580 - val_accuracy: 0.7380\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 17s 70ms/step - loss: 0.5370 - accuracy: 0.7942 - val_loss: 0.5554 - val_accuracy: 0.7842\n",
      "Generation #1, Genome #7, Fitness: [0.5468999743461609, 0.7379999756813049, 0.7842000126838684], Best Fitness: 0.7842000126838684\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 74ms/step - loss: 1.4902 - accuracy: 0.4227 - val_loss: 0.8261 - val_accuracy: 0.6814\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.8009 - accuracy: 0.6852 - val_loss: 0.9472 - val_accuracy: 0.6408\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.6461 - accuracy: 0.7470 - val_loss: 0.6126 - val_accuracy: 0.7425\n",
      "Generation #1, Genome #8, Fitness: [0.6814000010490417, 0.6407999992370605, 0.7425000071525574], Best Fitness: 0.7425000071525574\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 25s 74ms/step - loss: 1.2527 - accuracy: 0.5213 - val_loss: 0.7057 - val_accuracy: 0.7319\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.6546 - accuracy: 0.7508 - val_loss: 0.6082 - val_accuracy: 0.7689\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.5480 - accuracy: 0.7927 - val_loss: 0.5602 - val_accuracy: 0.7948\n",
      "Generation #1, Genome #9, Fitness: [0.7318999767303467, 0.7688999772071838, 0.7947999835014343], Best Fitness: 0.7947999835014343\n",
      "===== Generaton #1\tAll Fitness 0.7918000221252441 =====\n",
      "===== Generaton #1\tAll Fitness 0.7717999815940857 =====\n",
      "===== Generaton #1\tAll Fitness 0.7487000226974487 =====\n",
      "===== Generaton #1\tAll Fitness 0.7742000222206116 =====\n",
      "===== Generaton #1\tAll Fitness 0.7182000279426575 =====\n",
      "===== Generaton #1\tAll Fitness 0.7771999835968018 =====\n",
      "===== Generaton #1\tAll Fitness 0.7354000210762024 =====\n",
      "===== Generaton #1\tAll Fitness 0.7842000126838684 =====\n",
      "===== Generaton #1\tAll Fitness 0.7425000071525574 =====\n",
      "===== Generaton #1\tAll Fitness 0.7947999835014343 =====\n",
      "===== Generaton #1\tBest Fitness 0.7947999835014343 =====\n"
     ]
    }
   ],
   "source": [
    "# fitness는 TOP val_accuracy로 구성\n",
    "# score는 val_loss로 구성\n",
    "# genomes에 최종 학습이 끝난 epoch마다의 val_accuracy, bool_arr(layer별 얼릴 것인가 학습할 것인가) 정보가 포함되고 정렬됨\n",
    "\n",
    "n_gen = 0\n",
    "\n",
    "n_gen += 1\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "\n",
    "    genome = genomes[i]\n",
    "    model = genome.forward(0.0001)\n",
    "    history = genome.train_model(model, x_train, y_train, (x_test, y_test), epoch, batch_size)\n",
    "    fitness = history.history['val_accuracy']\n",
    "    sorted_fitness = sorted(fitness, reverse=True)\n",
    "    genome.fitness = sorted_fitness[0]\n",
    "\n",
    "    print('Generation #%s, Genome #%s, Fitness: %s, Best Fitness: %s' % (n_gen, i, fitness, genome.fitness))\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tAll Fitness %s =====\" % (n_gen, genomes[i].fitness))\n",
    "\n",
    "if best_genomes is not None:\n",
    "    genomes.extend(best_genomes)\n",
    "genomes.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "print('===== Generaton #%s\\tBest Fitness %s =====' % (n_gen, genomes[0].fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Generaton #1\tGenome #0 : Fitness 0.7947999835014343 =====\n",
      "===== Generaton #1\tGenome #1 : Fitness 0.7918000221252441 =====\n",
      "===== Generaton #1\tGenome #2 : Fitness 0.7842000126838684 =====\n",
      "===== Generaton #1\tGenome #3 : Fitness 0.7771999835968018 =====\n",
      "===== Generaton #1\tGenome #4 : Fitness 0.7742000222206116 =====\n",
      "===== Generaton #1\tGenome #5 : Fitness 0.7717999815940857 =====\n",
      "===== Generaton #1\tGenome #6 : Fitness 0.7487000226974487 =====\n",
      "===== Generaton #1\tGenome #7 : Fitness 0.7425000071525574 =====\n",
      "===== Generaton #1\tGenome #8 : Fitness 0.7354000210762024 =====\n",
      "===== Generaton #1\tGenome #9 : Fitness 0.7182000279426575 =====\n"
     ]
    }
   ],
   "source": [
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Generaton #1\tGenome #0 : Fitness 0.7947999835014343 =====\n",
      "===== Generaton #1\tGenome #1 : Fitness 0.7918000221252441 =====\n",
      "===== Generaton #1\tGenome #2 : Fitness 0.7842000126838684 =====\n",
      "===== Generaton #1\tGenome #3 : Fitness 0.7771999835968018 =====\n",
      "===== Generaton #1\tGenome #4 : Fitness 0.7742000222206116 =====\n",
      "===== Generaton #1\tGenome #5 : Fitness 0.7717999815940857 =====\n",
      "===== Generaton #1\tGenome #6 : Fitness 0.7487000226974487 =====\n",
      "===== Generaton #1\tGenome #7 : Fitness 0.7425000071525574 =====\n",
      "===== Generaton #1\tGenome #8 : Fitness 0.7354000210762024 =====\n",
      "===== Generaton #1\tGenome #9 : Fitness 0.7182000279426575 =====\n",
      "(10,)\n",
      "(10, 175)\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.array([])\n",
    "bool_arr = []\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "    # print(type(genome.bool_arr))\n",
    "    # print(genome.bool_arr)\n",
    "    accuracy = np.append(accuracy, genome.fitness)\n",
    "    # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "    bool_arr.append(genome.bool_arr)\n",
    "\n",
    "bool_arr = np.asarray(bool_arr)\n",
    "\n",
    "print(accuracy.shape)\n",
    "print(bool_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000002666FEA7740>\n"
     ]
    }
   ],
   "source": [
    "winner_acc = accuracy[:N_BEST]\n",
    "winner_bool_arr = bool_arr[:N_BEST]\n",
    "\n",
    "populationWinnerData = zip(winner_acc, winner_bool_arr)\n",
    "\n",
    "print(populationWinnerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "175 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "winner_acc = accuracy[:N_BEST]\n",
    "winner_bool_arr = bool_arr[:N_BEST]\n",
    "\n",
    "a_genome = deepcopy(winner_bool_arr[0])\n",
    "b_genome = deepcopy(winner_bool_arr[1])\n",
    "\n",
    "new_genome = []\n",
    "cut = np.random.randint(0, len(winner_bool_arr[0]))\n",
    "new_genome.extend(a_genome[:cut])\n",
    "new_genome.extend(b_genome[cut:])\n",
    "\n",
    "children = np.asarray(new_genome)\n",
    "\n",
    "print(cut)\n",
    "print(len(children), type(children))\n",
    "\n",
    "# print(crossover0.bool_arr is new_genome)\n",
    "\n",
    "# crossover0.set_bool_arr(new_genome)\n",
    "# print(crossover0.bool_arr is new_genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "flag = np.random.randint(0, len(winner_acc), size=2)\n",
    "print(flag)\n",
    "print(flag[0], flag[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_sequentail(iteration, winner_acc, winner_bool_arr, class_instance_arr):\n",
    "    \n",
    "    # max part는 추후 수정 예정\n",
    "    max = len(winner_acc)\n",
    "    if max < iteration:\n",
    "        for i in range(iteration-max):\n",
    "            winner_acc = np.append(winner_acc, winner_acc[i])\n",
    "            winner_bool_arr = np.append(winner_bool_arr, winner_bool_arr[i])\n",
    "\n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        a_genome = deepcopy(winner_bool_arr[i])\n",
    "        b_genome = deepcopy(winner_bool_arr[i-1])\n",
    "\n",
    "        new_genome = []\n",
    "        cut = np.random.randint(0, len(winner_bool_arr[0]))\n",
    "        new_genome.extend(a_genome[:cut])\n",
    "        new_genome.extend(b_genome[cut:])\n",
    "\n",
    "        children = np.asarray(new_genome)\n",
    "        genome.update_trainable(bool_arr=children)\n",
    "        avg_fitness = (winner_acc[i] + winner_acc[i-1])/2\n",
    "        genome.fitness = avg_fitness\n",
    "\n",
    "        print('Generation #%s, Crossover_sequence Genome #%s Created Bool_Array: %s layers, Predicted Fitness: %s, Done' % (n_gen, i, len(children), genome.fitness))\n",
    "\n",
    "\n",
    "def crossover_random(iteration, winner_acc, winner_bool_arr, class_instance_arr):\n",
    "\n",
    "    # max part는 추후 수정 예정\n",
    "    max = len(winner_acc)\n",
    "    if max < iteration:\n",
    "        for i in range(iteration-max):\n",
    "            winner_acc = np.append(winner_acc, winner_acc[i])\n",
    "            winner_bool_arr = np.append(winner_bool_arr, winner_bool_arr[i])\n",
    "    \n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        flag = np.random.randint(0, len(winner_acc), size=2)\n",
    "\n",
    "        a_genome = deepcopy(winner_bool_arr[flag[0]])\n",
    "        b_genome = deepcopy(winner_bool_arr[flag[-1]])\n",
    "\n",
    "        new_genome = []\n",
    "        cut = np.random.randint(0, len(winner_bool_arr[0]))\n",
    "        new_genome.extend(a_genome[:cut])\n",
    "        new_genome.extend(b_genome[cut:])\n",
    "\n",
    "        children = np.asarray(new_genome)\n",
    "        genome.update_trainable(bool_arr=children)\n",
    "        avg_fitness = (winner_acc[i] + winner_acc[i-1])/2\n",
    "        genome.fitness = avg_fitness\n",
    "\n",
    "        print('Generation #%s, Crossover_Random Genome #%s Created Bool_Array: %s layers, Predicted Fitness: %s, Done' % (n_gen, i, len(children), genome.fitness))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Generation #1, Crossover Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.784500002861023, Done\n",
      "Generation #1, Crossover Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.7933000028133392, Done\n",
      "Generation #1, Crossover Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.7880000174045563, Done\n",
      "Generation #1, Crossover Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7806999981403351, Done\n",
      "Generation #1, Crossover Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7757000029087067, Done\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# crossover Class Level with i and i-1\n",
    "crossovers = [Random_Finetune_ResNet50((32,32)) for _ in range(N_CHILDREN)]\n",
    "\n",
    "crossover_bool_arr = []\n",
    "for i, genome in enumerate(crossovers):\n",
    "    crossover_bool_arr.append(genome.bool_arr)\n",
    "    print(crossover_bool_arr[i] is crossovers[i].bool_arr)\n",
    "\n",
    "crossover_sequentail(winner_acc, winner_bool_arr, crossovers)\n",
    "print(crossover_bool_arr[0] is crossovers[0].bool_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Generation #1, Crossover Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.784500002861023, Done\n",
      "Generation #1, Crossover Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.7933000028133392, Done\n",
      "Generation #1, Crossover Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.7880000174045563, Done\n",
      "Generation #1, Crossover Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7806999981403351, Done\n",
      "Generation #1, Crossover Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7757000029087067, Done\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# crossover Class Level with RANDOM\n",
    "crossovers = [Random_Finetune_ResNet50((32,32)) for _ in range(N_CHILDREN)]\n",
    "\n",
    "crossover_bool_arr = []\n",
    "for i, genome in enumerate(crossovers):\n",
    "    crossover_bool_arr.append(genome.bool_arr)\n",
    "    print(crossover_bool_arr[i] is crossovers[i].bool_arr)\n",
    "\n",
    "crossover_random(winner_acc, winner_bool_arr, crossovers)\n",
    "print(crossover_bool_arr[0] is crossovers[0].bool_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation #1, Crossover Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.784500002861023, Done\n",
      "Generation #1, Crossover Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.7933000028133392, Done\n",
      "Generation #1, Crossover Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.7880000174045563, Done\n",
      "Generation #1, Crossover Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7806999981403351, Done\n",
      "Generation #1, Crossover Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7757000029087067, Done\n",
      "Generation #1, Crossover Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.784500002861023, Done\n",
      "Generation #1, Crossover Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.7933000028133392, Done\n",
      "Generation #1, Crossover Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.7880000174045563, Done\n",
      "Generation #1, Crossover Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7806999981403351, Done\n",
      "Generation #1, Crossover Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7757000029087067, Done\n"
     ]
    }
   ],
   "source": [
    "new_genomes = [Random_Finetune_ResNet50((32,32)) for _ in range(N_POPULATION)]\n",
    "\n",
    "crossover_sequentail(winner_acc, winner_bool_arr, new_genomes[:N_CHILDREN])\n",
    "crossover_sequentail(winner_acc, winner_bool_arr, new_genomes[N_CHILDREN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(winner_bool_arr, class_instance_arr):\n",
    "    \n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        print('Generation #%s, Genome #%s, Predicted Fitness: %s' % (n_gen, i, genome.fitness))\n",
    "        \n",
    "        mutation_copy_arr = deepcopy(genome.bool_arr)\n",
    "\n",
    "        if np.random.uniform(0,1) < PROB_MUTATION:\n",
    "\n",
    "            flag = np.random.randint(0, len(winner_bool_arr[0]))\n",
    "            flag = round(flag*PROB_MUTATION)\n",
    "\n",
    "            mutation_arr = random.sample(range(0, len(winner_bool_arr[0])), flag)\n",
    "            mutation_arr_sort = sorted(mutation_arr)\n",
    "            \n",
    "            for idx in mutation_arr_sort:\n",
    "                boolen = mutation_copy_arr[idx]\n",
    "                if boolen == True:\n",
    "                    mutation_copy_arr[idx] = False\n",
    "                else:\n",
    "                    mutation_copy_arr[idx] = True\n",
    "\n",
    "            genome.update_trainable(bool_arr=mutation_copy_arr)\n",
    "            \n",
    "            print('Generation #%s, Genome #%s, Mutation Happened!!! \\t size: %s, Mutation_Array: %s, Done' % (n_gen, i, flag, mutation_arr_sort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Generation #1, Genome #0, Predicted Fitness: 0.784500002861023\n",
      "Generation #1, Genome #1, Predicted Fitness: 0.7933000028133392\n",
      "Generation #1, Genome #1, Mutation Happened!!! \t size: 6, Mutation_Array: [10, 38, 44, 107, 119, 125], Done\n",
      "Generation #1, Genome #2, Predicted Fitness: 0.7880000174045563\n",
      "Generation #1, Genome #3, Predicted Fitness: 0.7806999981403351\n",
      "Generation #1, Genome #4, Predicted Fitness: 0.7757000029087067\n"
     ]
    }
   ],
   "source": [
    "crossover_bool_arr = []\n",
    "for i, genome in enumerate(crossovers):\n",
    "    crossover_bool_arr.append(genome.bool_arr)\n",
    "    print(crossover_bool_arr[i] is crossovers[i].bool_arr)\n",
    "\n",
    "mutation(winner_bool_arr, crossovers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(crossover_bool_arr[0] is crossovers[0].bool_arr)\n",
    "print(crossover_bool_arr[1] is crossovers[1].bool_arr)\n",
    "print(crossover_bool_arr[2] is crossovers[2].bool_arr)\n",
    "print(crossover_bool_arr[3] is crossovers[3].bool_arr)\n",
    "print(crossover_bool_arr[4] is crossovers[4].bool_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Generaton #0\tGenome #0 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #1 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #2 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #3 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #4 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #5 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #6 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #7 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #8 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #9 : Fitness 0 =====\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 74ms/step - loss: 1.9333 - accuracy: 0.2751 - val_loss: 1.0246 - val_accuracy: 0.6058\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.9759 - accuracy: 0.6156 - val_loss: 0.9328 - val_accuracy: 0.6353\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.7862 - accuracy: 0.6940 - val_loss: 0.8540 - val_accuracy: 0.6709\n",
      "Generation #1, Genome #0, Fitness: [0.6057999730110168, 0.6352999806404114, 0.6708999872207642], Best Fitness: 0.6708999872207642\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 70ms/step - loss: 1.2352 - accuracy: 0.5365 - val_loss: 0.6361 - val_accuracy: 0.7557\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.6132 - accuracy: 0.7631 - val_loss: 0.6303 - val_accuracy: 0.7636\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.5248 - accuracy: 0.7995 - val_loss: 0.5220 - val_accuracy: 0.8018\n",
      "Generation #1, Genome #1, Fitness: [0.7556999921798706, 0.7635999917984009, 0.801800012588501], Best Fitness: 0.801800012588501\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 73ms/step - loss: 1.5904 - accuracy: 0.3872 - val_loss: 1.0460 - val_accuracy: 0.5831\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.8407 - accuracy: 0.6676 - val_loss: 0.8265 - val_accuracy: 0.6684\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.7207 - accuracy: 0.7184 - val_loss: 0.7161 - val_accuracy: 0.7217\n",
      "Generation #1, Genome #2, Fitness: [0.5831000208854675, 0.66839998960495, 0.7217000126838684], Best Fitness: 0.7217000126838684\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 25s 73ms/step - loss: 1.7004 - accuracy: 0.3434 - val_loss: 0.9634 - val_accuracy: 0.5952\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 70ms/step - loss: 0.8080 - accuracy: 0.6857 - val_loss: 0.7333 - val_accuracy: 0.7133\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.6519 - accuracy: 0.7502 - val_loss: 0.6436 - val_accuracy: 0.7577\n",
      "Generation #1, Genome #3, Fitness: [0.5952000021934509, 0.7132999897003174, 0.7577000260353088], Best Fitness: 0.7577000260353088\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 26s 82ms/step - loss: 1.4916 - accuracy: 0.4283 - val_loss: 1.0006 - val_accuracy: 0.6081\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.7551 - accuracy: 0.7081 - val_loss: 0.7047 - val_accuracy: 0.7347\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.6428 - accuracy: 0.7506 - val_loss: 0.6041 - val_accuracy: 0.7616\n",
      "Generation #1, Genome #4, Fitness: [0.6080999970436096, 0.7347000241279602, 0.7616000175476074], Best Fitness: 0.7616000175476074\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 74ms/step - loss: 2.2766 - accuracy: 0.1590 - val_loss: 2.1655 - val_accuracy: 0.1354\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 2.0047 - accuracy: 0.2330 - val_loss: 1.5539 - val_accuracy: 0.3712\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.9921 - accuracy: 0.6004 - val_loss: 0.7995 - val_accuracy: 0.6868\n",
      "Generation #1, Genome #5, Fitness: [0.13539999723434448, 0.37119999527931213, 0.6868000030517578], Best Fitness: 0.6868000030517578\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 72ms/step - loss: 0.8631 - accuracy: 0.6721 - val_loss: 0.5465 - val_accuracy: 0.7948\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5073 - accuracy: 0.8090 - val_loss: 0.4982 - val_accuracy: 0.8176\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.4358 - accuracy: 0.8355 - val_loss: 0.4444 - val_accuracy: 0.8305\n",
      "Generation #1, Genome #6, Fitness: [0.7947999835014343, 0.8176000118255615, 0.8305000066757202], Best Fitness: 0.8305000066757202\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 25s 80ms/step - loss: 2.0944 - accuracy: 0.2164 - val_loss: 2.2207 - val_accuracy: 0.1146\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 1.6345 - accuracy: 0.3572 - val_loss: 1.4341 - val_accuracy: 0.4386\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 1.1304 - accuracy: 0.5607 - val_loss: 1.1334 - val_accuracy: 0.5671\n",
      "Generation #1, Genome #7, Fitness: [0.11460000276565552, 0.43860000371932983, 0.5670999884605408], Best Fitness: 0.5670999884605408\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 24s 74ms/step - loss: 1.2819 - accuracy: 0.5181 - val_loss: 0.7096 - val_accuracy: 0.7345\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.6716 - accuracy: 0.7370 - val_loss: 0.6111 - val_accuracy: 0.7583\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5815 - accuracy: 0.7761 - val_loss: 0.5570 - val_accuracy: 0.7909\n",
      "Generation #1, Genome #8, Fitness: [0.734499990940094, 0.7583000063896179, 0.7908999919891357], Best Fitness: 0.7908999919891357\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 72ms/step - loss: 1.1609 - accuracy: 0.5683 - val_loss: 0.6625 - val_accuracy: 0.7457\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.5749 - accuracy: 0.7811 - val_loss: 0.4867 - val_accuracy: 0.8150\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.4857 - accuracy: 0.8177 - val_loss: 0.4885 - val_accuracy: 0.8264\n",
      "Generation #1, Genome #9, Fitness: [0.7457000017166138, 0.8149999976158142, 0.8263999819755554], Best Fitness: 0.8263999819755554\n",
      "===== Generaton #1\t0 th Fitness 0.6708999872207642 =====\n",
      "===== Generaton #1\t1 th Fitness 0.801800012588501 =====\n",
      "===== Generaton #1\t2 th Fitness 0.7217000126838684 =====\n",
      "===== Generaton #1\t3 th Fitness 0.7577000260353088 =====\n",
      "===== Generaton #1\t4 th Fitness 0.7616000175476074 =====\n",
      "===== Generaton #1\t5 th Fitness 0.6868000030517578 =====\n",
      "===== Generaton #1\t6 th Fitness 0.8305000066757202 =====\n",
      "===== Generaton #1\t7 th Fitness 0.5670999884605408 =====\n",
      "===== Generaton #1\t8 th Fitness 0.7908999919891357 =====\n",
      "===== Generaton #1\t9 th Fitness 0.8263999819755554 =====\n",
      "===== Generaton #1\tBest Fitness 0.8305000066757202 =====\n",
      "===== Generaton #1\tGenome #0 : Fitness 0.8305000066757202 =====\n",
      "===== Generaton #1\tGenome #1 : Fitness 0.8263999819755554 =====\n",
      "===== Generaton #1\tGenome #2 : Fitness 0.801800012588501 =====\n",
      "===== Generaton #1\tGenome #3 : Fitness 0.7908999919891357 =====\n",
      "===== Generaton #1\tGenome #4 : Fitness 0.7616000175476074 =====\n",
      "===== Generaton #1\tGenome #5 : Fitness 0.7577000260353088 =====\n",
      "===== Generaton #1\tGenome #6 : Fitness 0.7217000126838684 =====\n",
      "===== Generaton #1\tGenome #7 : Fitness 0.6868000030517578 =====\n",
      "===== Generaton #1\tGenome #8 : Fitness 0.6708999872207642 =====\n",
      "===== Generaton #1\tGenome #9 : Fitness 0.5670999884605408 =====\n",
      " 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \n",
      "Generation #1, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.7941000163555145, Done\n",
      "Generation #1, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8284499943256378, Done\n",
      "Generation #1, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8140999972820282, Done\n",
      "Generation #1, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7963500022888184, Done\n",
      "Generation #1, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7762500047683716, Done\n",
      "Generation #1, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.7941000163555145, Done\n",
      "Generation #1, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8284499943256378, Done\n",
      "Generation #1, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8140999972820282, Done\n",
      "Generation #1, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7963500022888184, Done\n",
      "Generation #1, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7762500047683716, Done\n",
      "Generation #1, Genome #0, Predicted Fitness: 0.7941000163555145\n",
      "Generation #1, Genome #0, Mutation Happened!!! \t size: 4, Mutation_Array: [0, 92, 123, 136], Done\n",
      "Generation #1, Genome #1, Predicted Fitness: 0.8284499943256378\n",
      "Generation #1, Genome #2, Predicted Fitness: 0.8140999972820282\n",
      "Generation #1, Genome #3, Predicted Fitness: 0.7963500022888184\n",
      "Generation #1, Genome #4, Predicted Fitness: 0.7762500047683716\n",
      "Generation #1, Genome #4, Mutation Happened!!! \t size: 6, Mutation_Array: [3, 24, 60, 83, 124, 150], Done\n",
      "Generation #1, Genome #5, Predicted Fitness: 0.7941000163555145\n",
      "Generation #1, Genome #6, Predicted Fitness: 0.8284499943256378\n",
      "Generation #1, Genome #7, Predicted Fitness: 0.8140999972820282\n",
      "Generation #1, Genome #8, Predicted Fitness: 0.7963500022888184\n",
      "Generation #1, Genome #9, Predicted Fitness: 0.7762500047683716\n",
      "===== Generaton #1\tGenome #0 : Fitness 0.7941000163555145 =====\n",
      "===== Generaton #1\tGenome #1 : Fitness 0.8284499943256378 =====\n",
      "===== Generaton #1\tGenome #2 : Fitness 0.8140999972820282 =====\n",
      "===== Generaton #1\tGenome #3 : Fitness 0.7963500022888184 =====\n",
      "===== Generaton #1\tGenome #4 : Fitness 0.7762500047683716 =====\n",
      "===== Generaton #1\tGenome #5 : Fitness 0.7941000163555145 =====\n",
      "===== Generaton #1\tGenome #6 : Fitness 0.8284499943256378 =====\n",
      "===== Generaton #1\tGenome #7 : Fitness 0.8140999972820282 =====\n",
      "===== Generaton #1\tGenome #8 : Fitness 0.7963500022888184 =====\n",
      "===== Generaton #1\tGenome #9 : Fitness 0.7762500047683716 =====\n",
      " 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \n",
      "Generation #1, Done\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 72ms/step - loss: 1.1948 - accuracy: 0.5530 - val_loss: 0.8613 - val_accuracy: 0.6608\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.6831 - accuracy: 0.7349 - val_loss: 0.6212 - val_accuracy: 0.7617\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5979 - accuracy: 0.7684 - val_loss: 0.6160 - val_accuracy: 0.7594\n",
      "Generation #2, Genome #0, Fitness: [0.6607999801635742, 0.7616999745368958, 0.7594000101089478], Best Fitness: 0.7616999745368958\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 73ms/step - loss: 1.0150 - accuracy: 0.6138 - val_loss: 0.6821 - val_accuracy: 0.7499\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.5853 - accuracy: 0.7784 - val_loss: 0.6466 - val_accuracy: 0.7579\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5244 - accuracy: 0.8016 - val_loss: 0.6116 - val_accuracy: 0.7603\n",
      "Generation #2, Genome #1, Fitness: [0.7498999834060669, 0.7578999996185303, 0.7602999806404114], Best Fitness: 0.7602999806404114\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 71ms/step - loss: 2.0795 - accuracy: 0.2062 - val_loss: 1.3190 - val_accuracy: 0.4743\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.9827 - accuracy: 0.6034 - val_loss: 0.8309 - val_accuracy: 0.6867\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.7370 - accuracy: 0.7119 - val_loss: 0.7073 - val_accuracy: 0.7315\n",
      "Generation #2, Genome #2, Fitness: [0.47429999709129333, 0.6866999864578247, 0.7315000295639038], Best Fitness: 0.7315000295639038\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 72ms/step - loss: 0.8081 - accuracy: 0.6951 - val_loss: 0.5394 - val_accuracy: 0.7929\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.5102 - accuracy: 0.8049 - val_loss: 0.5562 - val_accuracy: 0.7934\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.4523 - accuracy: 0.8275 - val_loss: 0.4358 - val_accuracy: 0.8391\n",
      "Generation #2, Genome #3, Fitness: [0.792900025844574, 0.79339998960495, 0.8391000032424927], Best Fitness: 0.8391000032424927\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 74ms/step - loss: 1.1747 - accuracy: 0.5512 - val_loss: 0.6156 - val_accuracy: 0.7685\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 68ms/step - loss: 0.5583 - accuracy: 0.7902 - val_loss: 0.6049 - val_accuracy: 0.7686\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.4835 - accuracy: 0.8174 - val_loss: 0.4760 - val_accuracy: 0.8146\n",
      "Generation #2, Genome #4, Fitness: [0.7684999704360962, 0.7685999870300293, 0.8145999908447266], Best Fitness: 0.8145999908447266\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 25s 82ms/step - loss: 0.7460 - accuracy: 0.7180 - val_loss: 0.7211 - val_accuracy: 0.7316\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.5535 - accuracy: 0.7900 - val_loss: 0.5527 - val_accuracy: 0.7904\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 69ms/step - loss: 0.4982 - accuracy: 0.8114 - val_loss: 0.5422 - val_accuracy: 0.7907\n",
      "Generation #2, Genome #5, Fitness: [0.7315999865531921, 0.7904000282287598, 0.7907000184059143], Best Fitness: 0.7907000184059143\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 71ms/step - loss: 0.9245 - accuracy: 0.6446 - val_loss: 0.7017 - val_accuracy: 0.7383\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.6931 - accuracy: 0.7350 - val_loss: 0.6784 - val_accuracy: 0.7436\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.6111 - accuracy: 0.7657 - val_loss: 0.5802 - val_accuracy: 0.7779\n",
      "Generation #2, Genome #6, Fitness: [0.7383000254631042, 0.7436000108718872, 0.777899980545044], Best Fitness: 0.777899980545044\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 68ms/step - loss: 1.5886 - accuracy: 0.4049 - val_loss: 0.9477 - val_accuracy: 0.6405\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 63ms/step - loss: 0.7918 - accuracy: 0.7003 - val_loss: 0.6701 - val_accuracy: 0.7448\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 63ms/step - loss: 0.5960 - accuracy: 0.7765 - val_loss: 0.6258 - val_accuracy: 0.7672\n",
      "Generation #2, Genome #7, Fitness: [0.640500009059906, 0.7447999715805054, 0.7671999931335449], Best Fitness: 0.7671999931335449\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 69ms/step - loss: 1.0583 - accuracy: 0.5950 - val_loss: 0.7126 - val_accuracy: 0.7382\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.6287 - accuracy: 0.7589 - val_loss: 0.5927 - val_accuracy: 0.7680\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.5358 - accuracy: 0.7952 - val_loss: 0.5561 - val_accuracy: 0.7829\n",
      "Generation #2, Genome #8, Fitness: [0.7382000088691711, 0.7680000066757202, 0.7828999757766724], Best Fitness: 0.7828999757766724\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 76ms/step - loss: 1.4782 - accuracy: 0.4225 - val_loss: 0.9758 - val_accuracy: 0.6063\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.8390 - accuracy: 0.6670 - val_loss: 0.7321 - val_accuracy: 0.7161\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.7180 - accuracy: 0.7225 - val_loss: 0.6684 - val_accuracy: 0.7467\n",
      "Generation #2, Genome #9, Fitness: [0.6062999963760376, 0.7160999774932861, 0.7466999888420105], Best Fitness: 0.7466999888420105\n",
      "===== Generaton #2\t0 th Fitness 0.7616999745368958 =====\n",
      "===== Generaton #2\t1 th Fitness 0.7602999806404114 =====\n",
      "===== Generaton #2\t2 th Fitness 0.7315000295639038 =====\n",
      "===== Generaton #2\t3 th Fitness 0.8391000032424927 =====\n",
      "===== Generaton #2\t4 th Fitness 0.8145999908447266 =====\n",
      "===== Generaton #2\t5 th Fitness 0.7907000184059143 =====\n",
      "===== Generaton #2\t6 th Fitness 0.777899980545044 =====\n",
      "===== Generaton #2\t7 th Fitness 0.7671999931335449 =====\n",
      "===== Generaton #2\t8 th Fitness 0.7828999757766724 =====\n",
      "===== Generaton #2\t9 th Fitness 0.7466999888420105 =====\n",
      "===== Generaton #2\tBest Fitness 0.8391000032424927 =====\n",
      "===== Generaton #2\tGenome #0 : Fitness 0.8391000032424927 =====\n",
      "===== Generaton #2\tGenome #1 : Fitness 0.8145999908447266 =====\n",
      "===== Generaton #2\tGenome #2 : Fitness 0.7907000184059143 =====\n",
      "===== Generaton #2\tGenome #3 : Fitness 0.7828999757766724 =====\n",
      "===== Generaton #2\tGenome #4 : Fitness 0.777899980545044 =====\n",
      "===== Generaton #2\tGenome #5 : Fitness 0.7671999931335449 =====\n",
      "===== Generaton #2\tGenome #6 : Fitness 0.7616999745368958 =====\n",
      "===== Generaton #2\tGenome #7 : Fitness 0.7602999806404114 =====\n",
      "===== Generaton #2\tGenome #8 : Fitness 0.7466999888420105 =====\n",
      "===== Generaton #2\tGenome #9 : Fitness 0.7315000295639038 =====\n",
      " 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \n",
      "Generation #2, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.8031499981880188, Done\n",
      "Generation #2, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8268499970436096, Done\n",
      "Generation #2, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8026500046253204, Done\n",
      "Generation #2, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7867999970912933, Done\n",
      "Generation #2, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7803999781608582, Done\n",
      "Generation #2, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.8031499981880188, Done\n",
      "Generation #2, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8268499970436096, Done\n",
      "Generation #2, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8026500046253204, Done\n",
      "Generation #2, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.7867999970912933, Done\n",
      "Generation #2, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.7803999781608582, Done\n",
      "Generation #2, Genome #0, Predicted Fitness: 0.8031499981880188\n",
      "Generation #2, Genome #1, Predicted Fitness: 0.8268499970436096\n",
      "Generation #2, Genome #2, Predicted Fitness: 0.8026500046253204\n",
      "Generation #2, Genome #3, Predicted Fitness: 0.7867999970912933\n",
      "Generation #2, Genome #4, Predicted Fitness: 0.7803999781608582\n",
      "Generation #2, Genome #5, Predicted Fitness: 0.8031499981880188\n",
      "Generation #2, Genome #6, Predicted Fitness: 0.8268499970436096\n",
      "Generation #2, Genome #7, Predicted Fitness: 0.8026500046253204\n",
      "Generation #2, Genome #8, Predicted Fitness: 0.7867999970912933\n",
      "Generation #2, Genome #9, Predicted Fitness: 0.7803999781608582\n",
      "===== Generaton #2\tGenome #0 : Fitness 0.8031499981880188 =====\n",
      "===== Generaton #2\tGenome #1 : Fitness 0.8268499970436096 =====\n",
      "===== Generaton #2\tGenome #2 : Fitness 0.8026500046253204 =====\n",
      "===== Generaton #2\tGenome #3 : Fitness 0.7867999970912933 =====\n",
      "===== Generaton #2\tGenome #4 : Fitness 0.7803999781608582 =====\n",
      "===== Generaton #2\tGenome #5 : Fitness 0.8031499981880188 =====\n",
      "===== Generaton #2\tGenome #6 : Fitness 0.8268499970436096 =====\n",
      "===== Generaton #2\tGenome #7 : Fitness 0.8026500046253204 =====\n",
      "===== Generaton #2\tGenome #8 : Fitness 0.7867999970912933 =====\n",
      "===== Generaton #2\tGenome #9 : Fitness 0.7803999781608582 =====\n",
      " 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \n",
      "Generation #2, Done\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 68ms/step - loss: 0.8606 - accuracy: 0.6839 - val_loss: 0.6226 - val_accuracy: 0.7648\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 63ms/step - loss: 0.5493 - accuracy: 0.7921 - val_loss: 0.5283 - val_accuracy: 0.8022\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 62ms/step - loss: 0.4971 - accuracy: 0.8102 - val_loss: 0.5409 - val_accuracy: 0.8017\n",
      "Generation #3, Genome #0, Fitness: [0.7648000121116638, 0.8022000193595886, 0.8016999959945679], Best Fitness: 0.8022000193595886\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 69ms/step - loss: 0.9042 - accuracy: 0.6531 - val_loss: 0.5860 - val_accuracy: 0.7702\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.5467 - accuracy: 0.7929 - val_loss: 0.4987 - val_accuracy: 0.8113\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.4753 - accuracy: 0.8220 - val_loss: 0.4683 - val_accuracy: 0.8279\n",
      "Generation #3, Genome #1, Fitness: [0.7702000141143799, 0.8112999796867371, 0.8278999924659729], Best Fitness: 0.8278999924659729\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 71ms/step - loss: 0.7776 - accuracy: 0.7057 - val_loss: 0.6352 - val_accuracy: 0.7574\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 66ms/step - loss: 0.5115 - accuracy: 0.8069 - val_loss: 0.4784 - val_accuracy: 0.8227\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.4402 - accuracy: 0.8335 - val_loss: 0.4227 - val_accuracy: 0.8407\n",
      "Generation #3, Genome #2, Fitness: [0.7573999762535095, 0.822700023651123, 0.8406999707221985], Best Fitness: 0.8406999707221985\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 71ms/step - loss: 1.0641 - accuracy: 0.5969 - val_loss: 0.8464 - val_accuracy: 0.6816\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.5887 - accuracy: 0.7785 - val_loss: 0.7995 - val_accuracy: 0.7012\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.5273 - accuracy: 0.7988 - val_loss: 0.6970 - val_accuracy: 0.7417\n",
      "Generation #3, Genome #3, Fitness: [0.6815999746322632, 0.701200008392334, 0.7416999936103821], Best Fitness: 0.7416999936103821\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 69ms/step - loss: 0.7713 - accuracy: 0.7103 - val_loss: 0.6248 - val_accuracy: 0.7598\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.5531 - accuracy: 0.7891 - val_loss: 0.6361 - val_accuracy: 0.7549\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.5009 - accuracy: 0.8094 - val_loss: 0.4961 - val_accuracy: 0.8112\n",
      "Generation #3, Genome #4, Fitness: [0.7598000168800354, 0.7548999786376953, 0.8112000226974487], Best Fitness: 0.8112000226974487\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 67ms/step - loss: 0.7615 - accuracy: 0.7430 - val_loss: 0.4864 - val_accuracy: 0.8239\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 14s 62ms/step - loss: 0.4524 - accuracy: 0.8327 - val_loss: 0.4249 - val_accuracy: 0.8426\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 62ms/step - loss: 0.3981 - accuracy: 0.8519 - val_loss: 0.4069 - val_accuracy: 0.8496\n",
      "Generation #3, Genome #5, Fitness: [0.8238999843597412, 0.8425999879837036, 0.8496000170707703], Best Fitness: 0.8496000170707703\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 70ms/step - loss: 0.9228 - accuracy: 0.6488 - val_loss: 0.7145 - val_accuracy: 0.7290\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.5747 - accuracy: 0.7813 - val_loss: 0.5458 - val_accuracy: 0.7959\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.5151 - accuracy: 0.8033 - val_loss: 0.5340 - val_accuracy: 0.8060\n",
      "Generation #3, Genome #6, Fitness: [0.7289999723434448, 0.7958999872207642, 0.8059999942779541], Best Fitness: 0.8059999942779541\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 23s 73ms/step - loss: 0.5906 - accuracy: 0.7812 - val_loss: 0.4556 - val_accuracy: 0.8301\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.4173 - accuracy: 0.8444 - val_loss: 0.4304 - val_accuracy: 0.8348\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.3717 - accuracy: 0.8616 - val_loss: 0.3714 - val_accuracy: 0.8648\n",
      "Generation #3, Genome #7, Fitness: [0.8300999999046326, 0.8348000049591064, 0.864799976348877], Best Fitness: 0.864799976348877\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 72ms/step - loss: 1.0671 - accuracy: 0.5789 - val_loss: 0.7798 - val_accuracy: 0.6910\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.6859 - accuracy: 0.7355 - val_loss: 0.8709 - val_accuracy: 0.6550\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 16s 66ms/step - loss: 0.6238 - accuracy: 0.7587 - val_loss: 0.6414 - val_accuracy: 0.7491\n",
      "Generation #3, Genome #8, Fitness: [0.6909999847412109, 0.6549999713897705, 0.7491000294685364], Best Fitness: 0.7491000294685364\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 69ms/step - loss: 0.6813 - accuracy: 0.7401 - val_loss: 0.5661 - val_accuracy: 0.7838\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.5130 - accuracy: 0.8064 - val_loss: 0.4998 - val_accuracy: 0.8136\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.4557 - accuracy: 0.8267 - val_loss: 0.4692 - val_accuracy: 0.8249\n",
      "Generation #3, Genome #9, Fitness: [0.7838000059127808, 0.8136000037193298, 0.8248999714851379], Best Fitness: 0.8248999714851379\n",
      "===== Generaton #3\t0 th Fitness 0.8022000193595886 =====\n",
      "===== Generaton #3\t1 th Fitness 0.8278999924659729 =====\n",
      "===== Generaton #3\t2 th Fitness 0.8406999707221985 =====\n",
      "===== Generaton #3\t3 th Fitness 0.7416999936103821 =====\n",
      "===== Generaton #3\t4 th Fitness 0.8112000226974487 =====\n",
      "===== Generaton #3\t5 th Fitness 0.8496000170707703 =====\n",
      "===== Generaton #3\t6 th Fitness 0.8059999942779541 =====\n",
      "===== Generaton #3\t7 th Fitness 0.864799976348877 =====\n",
      "===== Generaton #3\t8 th Fitness 0.7491000294685364 =====\n",
      "===== Generaton #3\t9 th Fitness 0.8248999714851379 =====\n",
      "===== Generaton #3\tBest Fitness 0.864799976348877 =====\n",
      "===== Generaton #3\tGenome #0 : Fitness 0.864799976348877 =====\n",
      "===== Generaton #3\tGenome #1 : Fitness 0.8496000170707703 =====\n",
      "===== Generaton #3\tGenome #2 : Fitness 0.8406999707221985 =====\n",
      "===== Generaton #3\tGenome #3 : Fitness 0.8278999924659729 =====\n",
      "===== Generaton #3\tGenome #4 : Fitness 0.8248999714851379 =====\n",
      "===== Generaton #3\tGenome #5 : Fitness 0.8112000226974487 =====\n",
      "===== Generaton #3\tGenome #6 : Fitness 0.8059999942779541 =====\n",
      "===== Generaton #3\tGenome #7 : Fitness 0.8022000193595886 =====\n",
      "===== Generaton #3\tGenome #8 : Fitness 0.7491000294685364 =====\n",
      "===== Generaton #3\tGenome #9 : Fitness 0.7416999936103821 =====\n",
      " 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \n",
      "Generation #3, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.8379999995231628, Done\n",
      "Generation #3, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8571999967098236, Done\n",
      "Generation #3, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8451499938964844, Done\n",
      "Generation #3, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.8342999815940857, Done\n",
      "Generation #3, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.8263999819755554, Done\n",
      "Generation #3, Crossover_sequence Genome #0 Created Bool_Array: 175 layers, Predicted Fitness: 0.8379999995231628, Done\n",
      "Generation #3, Crossover_sequence Genome #1 Created Bool_Array: 175 layers, Predicted Fitness: 0.8571999967098236, Done\n",
      "Generation #3, Crossover_sequence Genome #2 Created Bool_Array: 175 layers, Predicted Fitness: 0.8451499938964844, Done\n",
      "Generation #3, Crossover_sequence Genome #3 Created Bool_Array: 175 layers, Predicted Fitness: 0.8342999815940857, Done\n",
      "Generation #3, Crossover_sequence Genome #4 Created Bool_Array: 175 layers, Predicted Fitness: 0.8263999819755554, Done\n",
      "Generation #3, Genome #0, Predicted Fitness: 0.8379999995231628\n",
      "Generation #3, Genome #1, Predicted Fitness: 0.8571999967098236\n",
      "Generation #3, Genome #2, Predicted Fitness: 0.8451499938964844\n",
      "Generation #3, Genome #3, Predicted Fitness: 0.8342999815940857\n",
      "Generation #3, Genome #4, Predicted Fitness: 0.8263999819755554\n",
      "Generation #3, Genome #5, Predicted Fitness: 0.8379999995231628\n",
      "Generation #3, Genome #6, Predicted Fitness: 0.8571999967098236\n",
      "Generation #3, Genome #7, Predicted Fitness: 0.8451499938964844\n",
      "Generation #3, Genome #8, Predicted Fitness: 0.8342999815940857\n",
      "Generation #3, Genome #9, Predicted Fitness: 0.8263999819755554\n",
      "===== Generaton #3\tGenome #0 : Fitness 0.8379999995231628 =====\n",
      "===== Generaton #3\tGenome #1 : Fitness 0.8571999967098236 =====\n",
      "===== Generaton #3\tGenome #2 : Fitness 0.8451499938964844 =====\n",
      "===== Generaton #3\tGenome #3 : Fitness 0.8342999815940857 =====\n",
      "===== Generaton #3\tGenome #4 : Fitness 0.8263999819755554 =====\n",
      "===== Generaton #3\tGenome #5 : Fitness 0.8379999995231628 =====\n",
      "===== Generaton #3\tGenome #6 : Fitness 0.8571999967098236 =====\n",
      "===== Generaton #3\tGenome #7 : Fitness 0.8451499938964844 =====\n",
      "===== Generaton #3\tGenome #8 : Fitness 0.8342999815940857 =====\n",
      "===== Generaton #3\tGenome #9 : Fitness 0.8263999819755554 =====\n",
      " 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \n",
      "Generation #3, Done\n",
      "Epoch 1/3\n",
      "235/235 [==============================] - 22s 70ms/step - loss: 0.6254 - accuracy: 0.7701 - val_loss: 0.4952 - val_accuracy: 0.8180\n",
      "Epoch 2/3\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GH\\Audio\\GA\\ga3.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000028?line=42'>43</a>\u001b[0m genome \u001b[39m=\u001b[39m genomes[i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000028?line=43'>44</a>\u001b[0m model \u001b[39m=\u001b[39m genome\u001b[39m.\u001b[39mforward(\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000028?line=44'>45</a>\u001b[0m history \u001b[39m=\u001b[39m genome\u001b[39m.\u001b[39;49mtrain_model(model, x_train, y_train, (x_test, y_test), epoch, batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000028?line=45'>46</a>\u001b[0m fitness \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000028?line=46'>47</a>\u001b[0m sorted_fitness \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(fitness, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32md:\\GH\\Audio\\GA\\ga3.ipynb Cell 4'\u001b[0m in \u001b[0;36mRandom_Finetune_ResNet50.train_model\u001b[1;34m(self, model, train_data, train_targets, validation_data, epochs, batch_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=43'>44</a>\u001b[0m checkpoint_best_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel_checkpoints_best/checkpoint\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=44'>45</a>\u001b[0m checkpoint_best \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39mcheckpoint_best_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=45'>46</a>\u001b[0m                                 save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=46'>47</a>\u001b[0m                                 save_freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=47'>48</a>\u001b[0m                                 monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=48'>49</a>\u001b[0m                                 save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=49'>50</a>\u001b[0m                                 verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=50'>51</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_data, train_targets,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=51'>52</a>\u001b[0m                 validation_data \u001b[39m=\u001b[39;49m validation_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=52'>53</a>\u001b[0m                 epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=53'>54</a>\u001b[0m                 batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=54'>55</a>\u001b[0m                 verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=55'>56</a>\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[early])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GH/Audio/GA/ga3.ipynb#ch0000003?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\keras\\engine\\training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1405'>1406</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1406'>1407</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1407'>1408</a>\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1408'>1409</a>\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1417'>1418</a>\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1418'>1419</a>\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1419'>1420</a>\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1420'>1421</a>\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1421'>1422</a>\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1422'>1423</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1423'>1424</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1424'>1425</a>\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1425'>1426</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1426'>1427</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1427'>1428</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1428'>1429</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1429'>1430</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1430'>1431</a>\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1431'>1432</a>\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1432'>1433</a>\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\keras\\engine\\training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1713'>1714</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1714'>1715</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1715'>1716</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1716'>1717</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/keras/engine/training.py?line=1717'>1718</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_py38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/angel/anaconda3/envs/tf_py38/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "N_POPULATION = 10\n",
    "N_BEST = 6\n",
    "N_CHILDREN = 5\n",
    "PROB_MUTATION = 0.04\n",
    "\n",
    "epoch = 3\n",
    "batch_size =256\n",
    "save_path = 'D:\\GH\\Audio\\GA\\pickle_data'\n",
    "\n",
    "# generate 1st population\n",
    "genomes = [Random_Finetune_ResNet50((32,32)) for _ in range(N_POPULATION)]\n",
    "nw_genomes = [Random_Finetune_ResNet50((32,32)) for _ in range(N_POPULATION)]\n",
    "\n",
    "n_gen = 0\n",
    "\n",
    "first_accuracy = np.array([])\n",
    "first_bool_arr = []\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "    # print(type(genome.bool_arr))\n",
    "    # print(genome.bool_arr)\n",
    "    first_accuracy = np.append(first_accuracy, genome.fitness)\n",
    "    # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "    first_bool_arr.append(genome.bool_arr)\n",
    "\n",
    "first_bool_arr = np.asarray(first_bool_arr)\n",
    "data = zip(first_accuracy, first_bool_arr)\n",
    "\n",
    "# save\n",
    "filename1 = '0_Generation_Bool_Arr.pickle'\n",
    "filepath = os.path.join(save_path, filename1)\n",
    "\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "while True:\n",
    "    n_gen += 1\n",
    "\n",
    "    for i, genome in enumerate(genomes):\n",
    "\n",
    "        genome = genomes[i]\n",
    "        model = genome.forward(0.0001)\n",
    "        history = genome.train_model(model, x_train, y_train, (x_test, y_test), epoch, batch_size)\n",
    "        fitness = history.history['val_accuracy']\n",
    "        sorted_fitness = sorted(fitness, reverse=True)\n",
    "        genome.fitness = sorted_fitness[0]\n",
    "\n",
    "        print('Generation #%s, Genome #%s, Fitness: %s, Best Fitness: %s' % (n_gen, i, fitness, genome.fitness))\n",
    "\n",
    "    for i, genome in enumerate(genomes):\n",
    "        print(\"===== Generaton #%s\\t%s th Fitness %s =====\" % (n_gen, i, genomes[i].fitness))\n",
    "\n",
    "    # if best_genomes is not None:\n",
    "    #     genomes.extend(best_genomes)\n",
    "    genomes.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "    print('===== Generaton #%s\\tBest Fitness %s =====' % (n_gen, genomes[0].fitness))\n",
    "\n",
    "    # 우성 genomes 를 만드는 과정\n",
    "    accuracy = np.array([])\n",
    "    bool_arr = []\n",
    "\n",
    "    for i, genome in enumerate(genomes):\n",
    "        print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "        # print(type(genome.bool_arr))\n",
    "        # print(genome.bool_arr)\n",
    "        accuracy = np.append(accuracy, genome.fitness)\n",
    "        # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "        bool_arr.append(genome.bool_arr)\n",
    "\n",
    "    bool_arr = np.asarray(bool_arr)\n",
    "\n",
    "    print(\" 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \")\n",
    "    # print(accuracy.shape)\n",
    "    # print(bool_arr.shape)\n",
    "\n",
    "    # 우성 bool_arr\n",
    "    winner_acc = accuracy[:N_BEST]\n",
    "    winner_bool_arr = bool_arr[:N_BEST]\n",
    "\n",
    "    # CROSSOVER with Sequantial\n",
    "    crossover_sequentail(N_CHILDREN, winner_acc, winner_bool_arr, nw_genomes[:N_CHILDREN])\n",
    "    crossover_sequentail(N_CHILDREN, winner_acc, winner_bool_arr, nw_genomes[N_CHILDREN:])\n",
    "\n",
    "    # mutation\n",
    "    mutation(winner_bool_arr, nw_genomes)\n",
    "\n",
    "    # 유전 연산 결과를 업데이트하는 과정\n",
    "    process_accuracy = np.array([])\n",
    "    process_bool_arr = []\n",
    "    for i, genome in enumerate(nw_genomes):\n",
    "        print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "        # print(type(genome.bool_arr))\n",
    "        # print(genome.bool_arr)\n",
    "        process_accuracy = np.append(process_accuracy, genome.fitness)\n",
    "        # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "        process_bool_arr.append(genome.bool_arr)\n",
    "\n",
    "    process_bool_arr = np.asarray(process_bool_arr)\n",
    "\n",
    "    print(\" 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \")\n",
    "    # print(process_accuracy.shape)\n",
    "    # print(process_bool_arr.shape)\n",
    "\n",
    "    for i, genome in enumerate(genomes):\n",
    "        genome.update_trainable(bool_arr=process_bool_arr[i])\n",
    "        genome.fitness = process_accuracy[i]\n",
    "\n",
    "    # genomes.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    print('Generation #%s, Done' % (n_gen))\n",
    "    data = zip(process_accuracy, process_bool_arr)\n",
    "\n",
    "    # save\n",
    "    filename = str(n_gen) + '_Generation_Bool_Arr.pickle'\n",
    "    filepath = os.path.join(save_path, filename)\n",
    "\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터를 저장하지 않으면 deepcopy가 진행되지 않는 것 같음\n",
    "\n",
    "# best_genomes = deepcopy(genomes[:1])\n",
    "\n",
    "# WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
    "# INFO:tensorflow:Assets written to: ram://d7898afe-6f2d-4baa-8dcd-cccd42f17e16/assets\n",
    "# FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://7fd86df0-a48d-49a8-955e-b376083fbc1e/variables/variables\n",
    "# You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` \n",
    "# to the io_device such as '/job:localhost'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'D:\\GH\\Audio\\GA\\pickle_data'\n",
    "filename1 = '1_Generation_Bool_Arr.pickle'\n",
    "filename2 = '1_Generation_Bool_Arr.pickle'\n",
    "\n",
    "filepath = os.path.join(save_path, filename1)\n",
    "\n",
    "# save\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "filepath = os.path.join(save_path, filename2)\n",
    "# load\n",
    "with open(filepath, 'rb') as f:\n",
    "    pair_data = pickle.load(f)\n",
    "print(pair_data.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20ea11077b4d33ea95f1fd00e03a9e40cb7cbf4ddc1b9ea71cbe1fbfe5e5187e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
