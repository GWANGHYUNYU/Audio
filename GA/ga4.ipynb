{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Dense, Flatten, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from IPython.display import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "# from tensorflow.keras.applications.resnet import ResNet101\n",
    "# from tensorflow.keras.applications.resnet150 import ResNet150\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "resnet50 = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(resnet50.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "# plot model architecture\n",
    "plot_model(resnet50, show_shapes=True, to_file='resnet50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 layer :   conv2_block1_1_conv\n",
      "8 layer :   conv2_block1_1_bn\n",
      "9 layer :   conv2_block1_1_relu\n",
      "10 layer :   conv2_block1_2_conv\n",
      "11 layer :   conv2_block1_2_bn\n",
      "12 layer :   conv2_block1_2_relu\n",
      "13 layer :   conv2_block1_0_conv\n",
      "14 layer :   conv2_block1_3_conv\n",
      "15 layer :   conv2_block1_0_bn\n",
      "16 layer :   conv2_block1_3_bn\n",
      "17 layer :   conv2_block1_add\n",
      "18 layer :   conv2_block1_out\n",
      "19 layer :   conv2_block2_1_conv\n",
      "20 layer :   conv2_block2_1_bn\n",
      "21 layer :   conv2_block2_1_relu\n",
      "22 layer :   conv2_block2_2_conv\n",
      "23 layer :   conv2_block2_2_bn\n",
      "24 layer :   conv2_block2_2_relu\n",
      "25 layer :   conv2_block2_3_conv\n",
      "26 layer :   conv2_block2_3_bn\n",
      "27 layer :   conv2_block2_add\n",
      "28 layer :   conv2_block2_out\n",
      "29 layer :   conv2_block3_1_conv\n",
      "30 layer :   conv2_block3_1_bn\n",
      "31 layer :   conv2_block3_1_relu\n",
      "32 layer :   conv2_block3_2_conv\n",
      "33 layer :   conv2_block3_2_bn\n",
      "34 layer :   conv2_block3_2_relu\n",
      "35 layer :   conv2_block3_3_conv\n",
      "36 layer :   conv2_block3_3_bn\n",
      "37 layer :   conv2_block3_add\n",
      "38 layer :   conv2_block3_out\n",
      "39 layer :   conv3_block1_1_conv\n",
      "40 layer :   conv3_block1_1_bn\n",
      "41 layer :   conv3_block1_1_relu\n",
      "42 layer :   conv3_block1_2_conv\n",
      "43 layer :   conv3_block1_2_bn\n",
      "44 layer :   conv3_block1_2_relu\n",
      "45 layer :   conv3_block1_0_conv\n",
      "46 layer :   conv3_block1_3_conv\n",
      "47 layer :   conv3_block1_0_bn\n",
      "48 layer :   conv3_block1_3_bn\n",
      "49 layer :   conv3_block1_add\n",
      "50 layer :   conv3_block1_out\n",
      "51 layer :   conv3_block2_1_conv\n",
      "52 layer :   conv3_block2_1_bn\n",
      "53 layer :   conv3_block2_1_relu\n",
      "54 layer :   conv3_block2_2_conv\n",
      "55 layer :   conv3_block2_2_bn\n",
      "56 layer :   conv3_block2_2_relu\n",
      "57 layer :   conv3_block2_3_conv\n",
      "58 layer :   conv3_block2_3_bn\n",
      "59 layer :   conv3_block2_add\n",
      "60 layer :   conv3_block2_out\n",
      "61 layer :   conv3_block3_1_conv\n",
      "62 layer :   conv3_block3_1_bn\n",
      "63 layer :   conv3_block3_1_relu\n",
      "64 layer :   conv3_block3_2_conv\n",
      "65 layer :   conv3_block3_2_bn\n",
      "66 layer :   conv3_block3_2_relu\n",
      "67 layer :   conv3_block3_3_conv\n",
      "68 layer :   conv3_block3_3_bn\n",
      "69 layer :   conv3_block3_add\n",
      "70 layer :   conv3_block3_out\n",
      "71 layer :   conv3_block4_1_conv\n",
      "72 layer :   conv3_block4_1_bn\n",
      "73 layer :   conv3_block4_1_relu\n",
      "74 layer :   conv3_block4_2_conv\n",
      "75 layer :   conv3_block4_2_bn\n",
      "76 layer :   conv3_block4_2_relu\n",
      "77 layer :   conv3_block4_3_conv\n",
      "78 layer :   conv3_block4_3_bn\n",
      "79 layer :   conv3_block4_add\n",
      "80 layer :   conv3_block4_out\n",
      "81 layer :   conv4_block1_1_conv\n",
      "82 layer :   conv4_block1_1_bn\n",
      "83 layer :   conv4_block1_1_relu\n",
      "84 layer :   conv4_block1_2_conv\n",
      "85 layer :   conv4_block1_2_bn\n",
      "86 layer :   conv4_block1_2_relu\n",
      "87 layer :   conv4_block1_0_conv\n",
      "88 layer :   conv4_block1_3_conv\n",
      "89 layer :   conv4_block1_0_bn\n",
      "90 layer :   conv4_block1_3_bn\n",
      "91 layer :   conv4_block1_add\n",
      "92 layer :   conv4_block1_out\n",
      "93 layer :   conv4_block2_1_conv\n",
      "94 layer :   conv4_block2_1_bn\n",
      "95 layer :   conv4_block2_1_relu\n",
      "96 layer :   conv4_block2_2_conv\n",
      "97 layer :   conv4_block2_2_bn\n",
      "98 layer :   conv4_block2_2_relu\n",
      "99 layer :   conv4_block2_3_conv\n",
      "100 layer :   conv4_block2_3_bn\n",
      "101 layer :   conv4_block2_add\n",
      "102 layer :   conv4_block2_out\n",
      "103 layer :   conv4_block3_1_conv\n",
      "104 layer :   conv4_block3_1_bn\n",
      "105 layer :   conv4_block3_1_relu\n",
      "106 layer :   conv4_block3_2_conv\n",
      "107 layer :   conv4_block3_2_bn\n",
      "108 layer :   conv4_block3_2_relu\n",
      "109 layer :   conv4_block3_3_conv\n",
      "110 layer :   conv4_block3_3_bn\n",
      "111 layer :   conv4_block3_add\n",
      "112 layer :   conv4_block3_out\n",
      "113 layer :   conv4_block4_1_conv\n",
      "114 layer :   conv4_block4_1_bn\n",
      "115 layer :   conv4_block4_1_relu\n",
      "116 layer :   conv4_block4_2_conv\n",
      "117 layer :   conv4_block4_2_bn\n",
      "118 layer :   conv4_block4_2_relu\n",
      "119 layer :   conv4_block4_3_conv\n",
      "120 layer :   conv4_block4_3_bn\n",
      "121 layer :   conv4_block4_add\n",
      "122 layer :   conv4_block4_out\n",
      "123 layer :   conv4_block5_1_conv\n",
      "124 layer :   conv4_block5_1_bn\n",
      "125 layer :   conv4_block5_1_relu\n",
      "126 layer :   conv4_block5_2_conv\n",
      "127 layer :   conv4_block5_2_bn\n",
      "128 layer :   conv4_block5_2_relu\n",
      "129 layer :   conv4_block5_3_conv\n",
      "130 layer :   conv4_block5_3_bn\n",
      "131 layer :   conv4_block5_add\n",
      "132 layer :   conv4_block5_out\n",
      "133 layer :   conv4_block6_1_conv\n",
      "134 layer :   conv4_block6_1_bn\n",
      "135 layer :   conv4_block6_1_relu\n",
      "136 layer :   conv4_block6_2_conv\n",
      "137 layer :   conv4_block6_2_bn\n",
      "138 layer :   conv4_block6_2_relu\n",
      "139 layer :   conv4_block6_3_conv\n",
      "140 layer :   conv4_block6_3_bn\n",
      "141 layer :   conv4_block6_add\n",
      "142 layer :   conv4_block6_out\n",
      "143 layer :   conv5_block1_1_conv\n",
      "144 layer :   conv5_block1_1_bn\n",
      "145 layer :   conv5_block1_1_relu\n",
      "146 layer :   conv5_block1_2_conv\n",
      "147 layer :   conv5_block1_2_bn\n",
      "148 layer :   conv5_block1_2_relu\n",
      "149 layer :   conv5_block1_0_conv\n",
      "150 layer :   conv5_block1_3_conv\n",
      "151 layer :   conv5_block1_0_bn\n",
      "152 layer :   conv5_block1_3_bn\n",
      "153 layer :   conv5_block1_add\n",
      "154 layer :   conv5_block1_out\n",
      "155 layer :   conv5_block2_1_conv\n",
      "156 layer :   conv5_block2_1_bn\n",
      "157 layer :   conv5_block2_1_relu\n",
      "158 layer :   conv5_block2_2_conv\n",
      "159 layer :   conv5_block2_2_bn\n",
      "160 layer :   conv5_block2_2_relu\n",
      "161 layer :   conv5_block2_3_conv\n",
      "162 layer :   conv5_block2_3_bn\n",
      "163 layer :   conv5_block2_add\n",
      "164 layer :   conv5_block2_out\n",
      "165 layer :   conv5_block3_1_conv\n",
      "166 layer :   conv5_block3_1_bn\n",
      "167 layer :   conv5_block3_1_relu\n",
      "168 layer :   conv5_block3_2_conv\n",
      "169 layer :   conv5_block3_2_bn\n",
      "170 layer :   conv5_block3_2_relu\n",
      "171 layer :   conv5_block3_3_conv\n",
      "172 layer :   conv5_block3_3_bn\n",
      "173 layer :   conv5_block3_add\n",
      "174 layer :   conv5_block3_out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nconv2_block1\\nconv2_block2\\nconv2_block3\\n\\nconv3_block1\\nconv3_block2\\nconv3_block3\\nconv3_block4\\n\\nconv4_block1\\nconv4_block2\\nconv4_block3\\nconv4_block4\\nconv4_block5\\nconv4_block6\\n\\nconv5_block1\\nconv5_block2\\nconv5_block3\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.trainable = True\t\t# resnet 모델 학습동결을 해제한다\n",
    "# for idx, i in enumerate(resnet50.layers):\t# 143층부터의 학습은 해제상태로 두고, \n",
    "#   i.trainable = bool_arr[idx]\t\t\t\t# 이전까지의 학습은 동결한다.\n",
    "\n",
    "idx = 0 \n",
    "for i in resnet50.layers[:]:\t# 동결이 제대로 해제됐는지 약간 이전층부터 출력해본다.\n",
    "  if i.name[:12] == 'conv2_block1':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv2_block2':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv2_block3':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "\n",
    "  elif i.name[:12] == 'conv3_block1':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv3_block2':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv3_block3':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv3_block4':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "\n",
    "  elif i.name[:12] == 'conv4_block1':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv4_block2':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv4_block3':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv4_block4':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv4_block5':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv4_block6':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "\n",
    "  elif i.name[:12] == 'conv5_block1':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv5_block2':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[:12] == 'conv5_block3':\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "    \n",
    "  idx += 1\n",
    "  \n",
    "'''\n",
    "conv2_block1\n",
    "conv2_block2\n",
    "conv2_block3\n",
    "\n",
    "conv3_block1\n",
    "conv3_block2\n",
    "conv3_block3\n",
    "conv3_block4\n",
    "\n",
    "conv4_block1\n",
    "conv4_block2\n",
    "conv4_block3\n",
    "conv4_block4\n",
    "conv4_block5\n",
    "conv4_block6\n",
    "\n",
    "conv5_block1\n",
    "conv5_block2\n",
    "conv5_block3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = MobileNet(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 16, 16, 32)        864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 16, 16, 32)       128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 16, 16, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 16, 16, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 16, 16, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)         576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 8, 8, 64)         256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 8, 8, 128)         8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)        1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 8, 8, 128)         16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 8, 8, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)        1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 4, 4, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 4, 4, 256)         32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 4, 4, 256)         65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 4, 4, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 2, 2, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 2, 2, 512)         131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 2, 2, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 2, 2, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 2, 2, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 2, 2, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 2, 2, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)        0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 1, 1, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 1, 1, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 1, 1, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 1, 1, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 1, 1, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 layer :   conv_dw_1\n",
      "5 layer :   conv_dw_1_bn\n",
      "6 layer :   conv_dw_1_relu\n",
      "7 layer :   conv_pw_1\n",
      "8 layer :   conv_pw_1_bn\n",
      "9 layer :   conv_pw_1_relu\n",
      "11 layer :   conv_dw_2\n",
      "12 layer :   conv_dw_2_bn\n",
      "13 layer :   conv_dw_2_relu\n",
      "14 layer :   conv_pw_2\n",
      "15 layer :   conv_pw_2_bn\n",
      "16 layer :   conv_pw_2_relu\n",
      "17 layer :   conv_dw_3\n",
      "18 layer :   conv_dw_3_bn\n",
      "19 layer :   conv_dw_3_relu\n",
      "20 layer :   conv_pw_3\n",
      "21 layer :   conv_pw_3_bn\n",
      "22 layer :   conv_pw_3_relu\n",
      "24 layer :   conv_dw_4\n",
      "25 layer :   conv_dw_4_bn\n",
      "26 layer :   conv_dw_4_relu\n",
      "27 layer :   conv_pw_4\n",
      "28 layer :   conv_pw_4_bn\n",
      "29 layer :   conv_pw_4_relu\n",
      "30 layer :   conv_dw_5\n",
      "31 layer :   conv_dw_5_bn\n",
      "32 layer :   conv_dw_5_relu\n",
      "33 layer :   conv_pw_5\n",
      "34 layer :   conv_pw_5_bn\n",
      "35 layer :   conv_pw_5_relu\n",
      "37 layer :   conv_dw_6\n",
      "38 layer :   conv_dw_6_bn\n",
      "39 layer :   conv_dw_6_relu\n",
      "40 layer :   conv_pw_6\n",
      "41 layer :   conv_pw_6_bn\n",
      "42 layer :   conv_pw_6_relu\n",
      "43 layer :   conv_dw_7\n",
      "44 layer :   conv_dw_7_bn\n",
      "45 layer :   conv_dw_7_relu\n",
      "46 layer :   conv_pw_7\n",
      "47 layer :   conv_pw_7_bn\n",
      "48 layer :   conv_pw_7_relu\n",
      "49 layer :   conv_dw_8\n",
      "50 layer :   conv_dw_8_bn\n",
      "51 layer :   conv_dw_8_relu\n",
      "52 layer :   conv_pw_8\n",
      "53 layer :   conv_pw_8_bn\n",
      "54 layer :   conv_pw_8_relu\n",
      "55 layer :   conv_dw_9\n",
      "56 layer :   conv_dw_9_bn\n",
      "57 layer :   conv_dw_9_relu\n",
      "58 layer :   conv_pw_9\n",
      "59 layer :   conv_pw_9_bn\n",
      "60 layer :   conv_pw_9_relu\n",
      "61 layer :   conv_dw_10\n",
      "62 layer :   conv_dw_10_bn\n",
      "63 layer :   conv_dw_10_relu\n",
      "64 layer :   conv_pw_10\n",
      "65 layer :   conv_pw_10_bn\n",
      "66 layer :   conv_pw_10_relu\n",
      "67 layer :   conv_dw_11\n",
      "68 layer :   conv_dw_11_bn\n",
      "69 layer :   conv_dw_11_relu\n",
      "70 layer :   conv_pw_11\n",
      "71 layer :   conv_pw_11_bn\n",
      "72 layer :   conv_pw_11_relu\n",
      "74 layer :   conv_dw_12\n",
      "75 layer :   conv_dw_12_bn\n",
      "76 layer :   conv_dw_12_relu\n",
      "77 layer :   conv_pw_12\n",
      "78 layer :   conv_pw_12_bn\n",
      "79 layer :   conv_pw_12_relu\n",
      "80 layer :   conv_dw_13\n",
      "81 layer :   conv_dw_13_bn\n",
      "82 layer :   conv_dw_13_relu\n",
      "83 layer :   conv_pw_13\n",
      "84 layer :   conv_pw_13_bn\n",
      "85 layer :   conv_pw_13_relu\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\t\t# resnet 모델 학습동결을 해제한다\n",
    "# for idx, i in enumerate(resnet50.layers):\t# 143층부터의 학습은 해제상태로 두고, \n",
    "#   i.trainable = bool_arr[idx]\t\t\t\t# 이전까지의 학습은 동결한다.\n",
    "\n",
    "idx = 0 \n",
    "for i in base_model.layers[:]:\t              # 13 Blocks in MobileNet\n",
    "  if i.name[7:9] == '_1' and idx == 4:\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[7:9] == '_1' and idx == 7:\n",
    "    print(idx, 'layer :  ', i.name)\n",
    "  elif i.name[7:10] == '_1_':\n",
    "    print(idx, 'layer :  ', i.name)           # 1st Block\n",
    "  elif i.name[7:9] == '_2':\n",
    "    print(idx, 'layer :  ', i.name)           # 2nd Block\n",
    "  elif i.name[7:9] == '_3':\n",
    "    print(idx, 'layer :  ', i.name)           # 3rd Block\n",
    "  elif i.name[7:9] == '_4':\n",
    "    print(idx, 'layer :  ', i.name)           # 4th Block\n",
    "  elif i.name[7:9] == '_5':\n",
    "    print(idx, 'layer :  ', i.name)           # 5th Block\n",
    "  elif i.name[7:9] == '_6':\n",
    "    print(idx, 'layer :  ', i.name)           # 6th Block\n",
    "  elif i.name[7:9] == '_7':\n",
    "    print(idx, 'layer :  ', i.name)           # 7th Block\n",
    "  elif i.name[7:9] == '_8':\n",
    "    print(idx, 'layer :  ', i.name)           # 8th Block\n",
    "  elif i.name[7:9] == '_9':\n",
    "    print(idx, 'layer :  ', i.name)           # 9th Block\n",
    "  elif i.name[7:10] == '_10':\n",
    "    print(idx, 'layer :  ', i.name)           # 10th Block\n",
    "  elif i.name[7:10] == '_11':\n",
    "    print(idx, 'layer :  ', i.name)           # 11th Block\n",
    "  elif i.name[7:10] == '_12':\n",
    "    print(idx, 'layer :  ', i.name)           # 12th Block\n",
    "  elif i.name[7:10] == '_13':\n",
    "    print(idx, 'layer :  ', i.name)           # 13th Block\n",
    "    \n",
    "  idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False  True  True  True  True  True False  True  True False\n",
      "  True False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "size = 4 + 13         # 17\n",
    "sample_arr = [True, False]\n",
    "bool_arr = np.random.choice(sample_arr, size=size)\n",
    "print(bool_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(base_model.layers):\n",
    "    if i.name[7:9] == '_1' and idx == 4:\n",
    "        if bool_arr[4] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[4] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_1' and idx == 7:\n",
    "        if bool_arr[4] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[4] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:10] == '_1_':\n",
    "        if bool_arr[4] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[4] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "\n",
    "    elif i.name[7:9] == '_2':\n",
    "        if bool_arr[5] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[5] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_3':\n",
    "        if bool_arr[6] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[6] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_4':\n",
    "        if bool_arr[7] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[7] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_5':\n",
    "        if bool_arr[8] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[8] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_6':\n",
    "        if bool_arr[9] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[9] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_7':\n",
    "        if bool_arr[10] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[10] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)                \n",
    "    elif i.name[7:9] == '_8':\n",
    "        if bool_arr[11] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[11] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:9] == '_9':\n",
    "        if bool_arr[12] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[12] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:10] == '_10':\n",
    "        if bool_arr[13] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[13] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:10] == '_11':\n",
    "        if bool_arr[14] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[14] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:10] == '_12':\n",
    "        if bool_arr[15] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[15] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)\n",
    "    elif i.name[7:10] == '_13':\n",
    "        if bool_arr[16] == True:\n",
    "            i.trainable = True\n",
    "        elif bool_arr[16] == False:\n",
    "            i.trainable = False\n",
    "        # print(idx, 'layer : ', i.name, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 layer :  input_1 -> True\n",
      "1 layer :  conv1 -> True\n",
      "2 layer :  conv1_bn -> True\n",
      "3 layer :  conv1_relu -> True\n",
      "4 layer :  conv_dw_1 -> True\n",
      "5 layer :  conv_dw_1_bn -> True\n",
      "6 layer :  conv_dw_1_relu -> True\n",
      "7 layer :  conv_pw_1 -> True\n",
      "8 layer :  conv_pw_1_bn -> True\n",
      "9 layer :  conv_pw_1_relu -> True\n",
      "10 layer :  conv_pad_2 -> True\n",
      "11 layer :  conv_dw_2 -> True\n",
      "12 layer :  conv_dw_2_bn -> True\n",
      "13 layer :  conv_dw_2_relu -> True\n",
      "14 layer :  conv_pw_2 -> True\n",
      "15 layer :  conv_pw_2_bn -> True\n",
      "16 layer :  conv_pw_2_relu -> True\n",
      "17 layer :  conv_dw_3 -> True\n",
      "18 layer :  conv_dw_3_bn -> True\n",
      "19 layer :  conv_dw_3_relu -> True\n",
      "20 layer :  conv_pw_3 -> True\n",
      "21 layer :  conv_pw_3_bn -> True\n",
      "22 layer :  conv_pw_3_relu -> True\n",
      "23 layer :  conv_pad_4 -> True\n",
      "24 layer :  conv_dw_4 -> True\n",
      "25 layer :  conv_dw_4_bn -> True\n",
      "26 layer :  conv_dw_4_relu -> True\n",
      "27 layer :  conv_pw_4 -> True\n",
      "28 layer :  conv_pw_4_bn -> True\n",
      "29 layer :  conv_pw_4_relu -> True\n",
      "30 layer :  conv_dw_5 -> False\n",
      "31 layer :  conv_dw_5_bn -> False\n",
      "32 layer :  conv_dw_5_relu -> False\n",
      "33 layer :  conv_pw_5 -> False\n",
      "34 layer :  conv_pw_5_bn -> False\n",
      "35 layer :  conv_pw_5_relu -> False\n",
      "36 layer :  conv_pad_6 -> True\n",
      "37 layer :  conv_dw_6 -> True\n",
      "38 layer :  conv_dw_6_bn -> True\n",
      "39 layer :  conv_dw_6_relu -> True\n",
      "40 layer :  conv_pw_6 -> True\n",
      "41 layer :  conv_pw_6_bn -> True\n",
      "42 layer :  conv_pw_6_relu -> True\n",
      "43 layer :  conv_dw_7 -> True\n",
      "44 layer :  conv_dw_7_bn -> True\n",
      "45 layer :  conv_dw_7_relu -> True\n",
      "46 layer :  conv_pw_7 -> True\n",
      "47 layer :  conv_pw_7_bn -> True\n",
      "48 layer :  conv_pw_7_relu -> True\n",
      "49 layer :  conv_dw_8 -> False\n",
      "50 layer :  conv_dw_8_bn -> False\n",
      "51 layer :  conv_dw_8_relu -> False\n",
      "52 layer :  conv_pw_8 -> False\n",
      "53 layer :  conv_pw_8_bn -> False\n",
      "54 layer :  conv_pw_8_relu -> False\n",
      "55 layer :  conv_dw_9 -> True\n",
      "56 layer :  conv_dw_9_bn -> True\n",
      "57 layer :  conv_dw_9_relu -> True\n",
      "58 layer :  conv_pw_9 -> True\n",
      "59 layer :  conv_pw_9_bn -> True\n",
      "60 layer :  conv_pw_9_relu -> True\n",
      "61 layer :  conv_dw_10 -> False\n",
      "62 layer :  conv_dw_10_bn -> False\n",
      "63 layer :  conv_dw_10_relu -> False\n",
      "64 layer :  conv_pw_10 -> False\n",
      "65 layer :  conv_pw_10_bn -> False\n",
      "66 layer :  conv_pw_10_relu -> False\n",
      "67 layer :  conv_dw_11 -> True\n",
      "68 layer :  conv_dw_11_bn -> True\n",
      "69 layer :  conv_dw_11_relu -> True\n",
      "70 layer :  conv_pw_11 -> True\n",
      "71 layer :  conv_pw_11_bn -> True\n",
      "72 layer :  conv_pw_11_relu -> True\n",
      "73 layer :  conv_pad_12 -> True\n",
      "74 layer :  conv_dw_12 -> True\n",
      "75 layer :  conv_dw_12_bn -> True\n",
      "76 layer :  conv_dw_12_relu -> True\n",
      "77 layer :  conv_pw_12 -> True\n",
      "78 layer :  conv_pw_12_bn -> True\n",
      "79 layer :  conv_pw_12_relu -> True\n",
      "80 layer :  conv_dw_13 -> True\n",
      "81 layer :  conv_dw_13_bn -> True\n",
      "82 layer :  conv_dw_13_relu -> True\n",
      "83 layer :  conv_pw_13 -> True\n",
      "84 layer :  conv_pw_13_bn -> True\n",
      "85 layer :  conv_pw_13_relu -> True\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(base_model.layers):\n",
    "    print(idx, 'layer : ', i.name, '->' ,i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 2s 0us/step\n",
      "9420800/9406464 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array: \n",
      "[ True False False  True False False False False False False False  True\n",
      "  True False  True  True  True  True  True]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sample_arr = [True, False]\n",
    "bool_arr = np.random.choice(sample_arr, size=len(base_model.layers))\n",
    "print('Numpy Array: ')\n",
    "print(bool_arr)\n",
    "print(len(bool_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = tf.keras.applications.resnet.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 21s 0us/step\n",
      "171458560/171446536 [==============================] - 21s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = tf.keras.applications.resnet.ResNet101(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234700800/234698864 [==============================] - 23s 0us/step\n",
      "234708992/234698864 [==============================] - 23s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = tf.keras.applications.resnet.ResNet152(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB1\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB6\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 2s 0us/step\n",
      "16719872/16705208 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = EfficientNetB0(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "27025408/27018416 [==============================] - 2s 0us/step\n",
      "27033600/27018416 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (32, 32, 3)\n",
    "base_model = EfficientNetB1(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "len(base_model.layers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba2a1a9e688c13729bc3ce039aebfba3ed6aba2e3ff21806c4b0dd9559fdc94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
