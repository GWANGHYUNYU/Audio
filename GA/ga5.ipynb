{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Dense, Flatten, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from IPython.display import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Finetune_ResNet50():\n",
    "    def __init__(self, input_shape, freezing_layer_flag):\n",
    "\n",
    "        self.fitness = 0\n",
    "        # self.loss = 1000\n",
    "        \n",
    "        IMG_SHAPE = input_shape + (3,)\n",
    "        self.base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "        self.size = 7 + 3 + 4 + 6 + 3        # 23\n",
    "        sample_arr = [True, False]\n",
    "        self.bool_arr = np.random.choice(sample_arr, size=self.size)\n",
    "        self.bool_arr[:freezing_layer_flag] = False\n",
    "        self.update_trainable()\n",
    "        # self.base_model.trainable = True\n",
    "        # for idx, i in enumerate(self.base_model.layers):\n",
    "        #     i.trainable = self.bool_arr[idx]\n",
    "    \n",
    "    def update_trainable(self, bool_arr=None):\n",
    "        if bool_arr is not None: \n",
    "            self.bool_arr = bool_arr\n",
    "        self.base_model.trainable = True\n",
    "        for idx, i in enumerate(self.base_model.layers):\n",
    "            if i.name[:12] == 'conv2_block1':\n",
    "                if self.bool_arr[7] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[7] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv2_block2':\n",
    "                if self.bool_arr[8] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[8] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv2_block3':\n",
    "                if self.bool_arr[9] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[9] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "\n",
    "            elif i.name[:12] == 'conv3_block1':\n",
    "                if self.bool_arr[10] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[10] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv3_block2':\n",
    "                if self.bool_arr[11] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[11] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv3_block3':\n",
    "                if self.bool_arr[12] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[12] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv3_block4':\n",
    "                if self.bool_arr[13] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[13] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "\n",
    "            elif i.name[:12] == 'conv4_block1':\n",
    "                if self.bool_arr[14] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[14] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv4_block2':\n",
    "                if self.bool_arr[15] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[15] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv4_block3':\n",
    "                if self.bool_arr[16] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[16] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv4_block4':\n",
    "                if self.bool_arr[17] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[17] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv4_block5':\n",
    "                if self.bool_arr[18] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[18] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv4_block6':\n",
    "                if self.bool_arr[19] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[19] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "\n",
    "            elif i.name[:12] == 'conv5_block1':\n",
    "                if self.bool_arr[20] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[20] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv5_block2':\n",
    "                if self.bool_arr[21] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[21] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "            elif i.name[:12] == 'conv5_block3':\n",
    "                if self.bool_arr[22] == True:\n",
    "                    i.trainable = True\n",
    "                elif self.bool_arr[22] == False:\n",
    "                    i.trainable = False\n",
    "                # print(idx, 'layer : ', i.name, i.trainable)\n",
    "        \n",
    "    def forward(self, learning_rate=0.001):\n",
    "        inputs = Input((28, 28, 1))\n",
    "        resized_x = tf.keras.layers.experimental.preprocessing.Resizing(32, 32)(inputs)\n",
    "        first_conv_layer = Conv2D(3, 1, padding='same', activation=None)(resized_x)\n",
    "\n",
    "        x = self.base_model(first_conv_layer, training = False)\n",
    "        x = Flatten()(x)\n",
    "        outputs = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs, name=\"fashion_mnist_resnet50_model\")\n",
    "\n",
    "        # 'categorical_crossentropy'은 y[0]=[0, 0, 0, 0, 0, 0, 0, 0, 1], y[1, 0, 0, 0, 0, 0, 0, 0, 0]과 같이 one-hot-encoding label일 경우에 사용\n",
    "        model.compile(loss=\"categorical_crossentropy\", \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate= learning_rate), \n",
    "        metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, model, train_data, train_targets, validation_data=(x_test, y_test), epochs=20, batch_size=256):\n",
    "    \n",
    "        early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        checkpoint_best_path = 'model_checkpoints_best/checkpoint'\n",
    "        checkpoint_best = ModelCheckpoint(filepath=checkpoint_best_path,\n",
    "                                        save_weights_only=True,\n",
    "                                        save_freq='epoch',\n",
    "                                        monitor='val_accuracy',\n",
    "                                        save_best_only=True,\n",
    "                                        verbose=1)\n",
    "        history = model.fit(train_data, train_targets,\n",
    "                        validation_data = validation_data,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        verbose = 1,\n",
    "                        callbacks=[early])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_POPULATION = 4\n",
    "N_BEST = 2\n",
    "N_CHILDREN = 2\n",
    "PROB_MUTATION = 0.04\n",
    "\n",
    "n_gen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_sequentail(iteration, winner_acc, winner_bool_arr, class_instance_arr, freezing_flag):\n",
    "    \n",
    "    # max part는 추후 수정 예정\n",
    "    max = len(winner_acc)\n",
    "    if max < iteration:\n",
    "        for i in range(iteration-max):\n",
    "            winner_acc = np.append(winner_acc, winner_acc[i])\n",
    "            winner_bool_arr = np.append(winner_bool_arr, winner_bool_arr[i])\n",
    "\n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        a_genome = deepcopy(winner_bool_arr[i])\n",
    "        b_genome = deepcopy(winner_bool_arr[i-1])\n",
    "\n",
    "        new_genome = []\n",
    "        cut = np.random.randint(freezing_flag, len(winner_bool_arr[0]))\n",
    "        new_genome.extend(a_genome[:cut])\n",
    "        new_genome.extend(b_genome[cut:])\n",
    "\n",
    "        children = np.asarray(new_genome)\n",
    "        genome.update_trainable(bool_arr=children)\n",
    "        avg_fitness = (winner_acc[i] + winner_acc[i-1])/2\n",
    "        genome.fitness = avg_fitness\n",
    "\n",
    "        print('Generation #%s, Crossover_sequence Genome #%s Created Bool_Array: %s layers, Predicted Fitness: %s, Done' % (n_gen, i, len(children), genome.fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_random(iteration, winner_acc, winner_bool_arr, class_instance_arr, freezing_flag):\n",
    "\n",
    "    # max part는 추후 수정 예정\n",
    "    max = len(winner_acc)\n",
    "    if max < iteration:\n",
    "        for i in range(iteration-max):\n",
    "            winner_acc = np.append(winner_acc, winner_acc[i])\n",
    "            winner_bool_arr = np.append(winner_bool_arr, winner_bool_arr[i])\n",
    "    \n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        flag = np.random.randint(freezing_flag, len(winner_acc), size=2)\n",
    "\n",
    "        a_genome = deepcopy(winner_bool_arr[flag[0]])\n",
    "        b_genome = deepcopy(winner_bool_arr[flag[-1]])\n",
    "\n",
    "        new_genome = []\n",
    "        cut = np.random.randint(0, len(winner_bool_arr[0]))\n",
    "        new_genome.extend(a_genome[:cut])\n",
    "        new_genome.extend(b_genome[cut:])\n",
    "\n",
    "        children = np.asarray(new_genome)\n",
    "        genome.update_trainable(bool_arr=children)\n",
    "        avg_fitness = (winner_acc[i] + winner_acc[i-1])/2\n",
    "        genome.fitness = avg_fitness\n",
    "\n",
    "        print('Generation #%s, Crossover_Random Genome #%s Created Bool_Array: %s layers, Predicted Fitness: %s, Done' % (n_gen, i, len(children), genome.fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(winner_bool_arr, class_instance_arr, freezing_layer_flag):\n",
    "    \n",
    "    for i, genome in enumerate(class_instance_arr):\n",
    "\n",
    "        print('Generation #%s, Genome #%s, Predicted Fitness: %s' % (n_gen, i, genome.fitness))\n",
    "        \n",
    "        mutation_copy_arr = deepcopy(genome.bool_arr)\n",
    "\n",
    "        if np.random.uniform(0,1) < PROB_MUTATION:\n",
    "\n",
    "            flag = np.random.randint(0, genome.size)\n",
    "            flag = round(flag*PROB_MUTATION)\n",
    "\n",
    "            mutation_arr = random.sample(range(freezing_layer_flag, genome.size), flag)\n",
    "            mutation_arr_sort = sorted(mutation_arr)\n",
    "            \n",
    "            for idx in mutation_arr_sort:\n",
    "                boolen = mutation_copy_arr[idx]\n",
    "                if boolen == True:\n",
    "                    mutation_copy_arr[idx] = False\n",
    "                else:\n",
    "                    mutation_copy_arr[idx] = True\n",
    "\n",
    "            genome.update_trainable(bool_arr=mutation_copy_arr)\n",
    "            \n",
    "            print('Generation #%s, Genome #%s, Mutation Happened!!! \\t size: %s, Mutation_Array: %s, Done' % (n_gen, i, flag, mutation_arr_sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1st population\n",
    "genomes = [Random_Finetune_ResNet50((32,32), 0) for _ in range(N_POPULATION)]\n",
    "nw_genomes = [Random_Finetune_ResNet50((32,32), 0) for _ in range(N_POPULATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Generaton #0\tGenome #0 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #1 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #2 : Fitness 0 =====\n",
      "===== Generaton #0\tGenome #3 : Fitness 0 =====\n"
     ]
    }
   ],
   "source": [
    "first_accuracy = np.array([])\n",
    "first_bool_arr = []\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "    # print(type(genome.bool_arr))\n",
    "    # print(genome.bool_arr)\n",
    "    first_accuracy = np.append(first_accuracy, genome.fitness)\n",
    "    # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "    first_bool_arr.append(genome.bool_arr)\n",
    "\n",
    "first_bool_arr = np.asarray(first_bool_arr)\n",
    "data = zip(first_accuracy, first_bool_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Generaton #3\t START ======================\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 23s 72ms/step - loss: 0.6773 - accuracy: 0.7460 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 16s 67ms/step - loss: 0.4470 - accuracy: 0.8335 - val_loss: 0.4030 - val_accuracy: 0.8508\n",
      "Generation #3, Genome #0, Fitness: [0.800000011920929, 0.8507999777793884], Best Fitness: 0.8507999777793884\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 22s 69ms/step - loss: 0.6429 - accuracy: 0.7620 - val_loss: 0.4902 - val_accuracy: 0.8112\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.4282 - accuracy: 0.8389 - val_loss: 0.4156 - val_accuracy: 0.8466\n",
      "Generation #3, Genome #1, Fitness: [0.8112000226974487, 0.8465999960899353], Best Fitness: 0.8465999960899353\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 22s 70ms/step - loss: 1.0996 - accuracy: 0.5798 - val_loss: 0.6725 - val_accuracy: 0.7374\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.5921 - accuracy: 0.7692 - val_loss: 0.5214 - val_accuracy: 0.8045\n",
      "Generation #3, Genome #2, Fitness: [0.7373999953269958, 0.8044999837875366], Best Fitness: 0.8044999837875366\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 23s 71ms/step - loss: 1.3900 - accuracy: 0.4760 - val_loss: 0.8111 - val_accuracy: 0.6583\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 15s 65ms/step - loss: 0.7020 - accuracy: 0.7297 - val_loss: 0.6647 - val_accuracy: 0.7365\n",
      "Generation #3, Genome #3, Fitness: [0.65829998254776, 0.7365000247955322], Best Fitness: 0.7365000247955322\n",
      "===== Generaton #3\t0 th Fitness 0.8507999777793884 =====\n",
      "===== Generaton #3\t1 th Fitness 0.8465999960899353 =====\n",
      "===== Generaton #3\t2 th Fitness 0.8044999837875366 =====\n",
      "===== Generaton #3\t3 th Fitness 0.7365000247955322 =====\n",
      "===== Generaton #3\tBest Fitness 0.8507999777793884 =====\n",
      "===== Generaton #3\tGenome #0 : Fitness 0.8507999777793884 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False  True False  True  True]\n",
      "===== Generaton #3\tGenome #1 : Fitness 0.8465999960899353 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False False False False  True]\n",
      "===== Generaton #3\tGenome #2 : Fitness 0.8044999837875366 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True False  True  True\n",
      " False False  True False False  True False  True False  True  True]\n",
      "===== Generaton #3\tGenome #3 : Fitness 0.7365000247955322 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False False False  True  True  True  True False  True\n",
      " False  True  True  True False  True False False False False  True]\n",
      " 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \n",
      "(4,)\n",
      "(4, 23)\n",
      "Generation #3, Crossover_sequence Genome #0 Created Bool_Array: 23 layers, Predicted Fitness: 0.8486999869346619, Done\n",
      "Generation #3, Crossover_sequence Genome #1 Created Bool_Array: 23 layers, Predicted Fitness: 0.8486999869346619, Done\n",
      "Generation #3, Crossover_sequence Genome #0 Created Bool_Array: 23 layers, Predicted Fitness: 0.8486999869346619, Done\n",
      "Generation #3, Crossover_sequence Genome #1 Created Bool_Array: 23 layers, Predicted Fitness: 0.8486999869346619, Done\n",
      "Generation #3, Genome #0, Predicted Fitness: 0.8486999869346619\n",
      "Generation #3, Genome #1, Predicted Fitness: 0.8486999869346619\n",
      "Generation #3, Genome #2, Predicted Fitness: 0.8486999869346619\n",
      "Generation #3, Genome #3, Predicted Fitness: 0.8486999869346619\n",
      "===== Generaton #3\tGenome #0 : Fitness 0.8486999869346619 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False False False False  True]\n",
      "===== Generaton #3\tGenome #1 : Fitness 0.8486999869346619 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False  True False  True  True]\n",
      "===== Generaton #3\tGenome #2 : Fitness 0.8486999869346619 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False False False False  True]\n",
      "===== Generaton #3\tGenome #3 : Fitness 0.8486999869346619 =====\n",
      "<class 'numpy.ndarray'>\n",
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False  True  True  True False  True False  True False  True  True]\n",
      " 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \n",
      "(4,)\n",
      "(4, 23)\n",
      "Generation #3, Done\n"
     ]
    }
   ],
   "source": [
    "n_gen += 1\n",
    "epoch = 2\n",
    "batch_size = 256\n",
    "\n",
    "print(\"====================== Generaton #%s\\t START ======================\" % (n_gen))\n",
    "for i, genome in enumerate(genomes):\n",
    "\n",
    "    genome = genomes[i]\n",
    "    model = genome.forward(0.0001)\n",
    "    history = genome.train_model(model, x_train, y_train, (x_test, y_test), epoch, batch_size)\n",
    "    fitness = history.history['val_accuracy']\n",
    "    sorted_fitness = sorted(fitness, reverse=True)\n",
    "    genome.fitness = sorted_fitness[0]\n",
    "\n",
    "    print('Generation #%s, Genome #%s, Fitness: %s, Best Fitness: %s' % (n_gen, i, fitness, genome.fitness))\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\t%s th Fitness %s =====\" % (n_gen, i, genomes[i].fitness))\n",
    "\n",
    "# if best_genomes is not None:\n",
    "#     genomes.extend(best_genomes)\n",
    "genomes.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "print('===== Generaton #%s\\tBest Fitness %s =====' % (n_gen, genomes[0].fitness))\n",
    "\n",
    "# 우성 genomes 를 만드는 과정\n",
    "accuracy = np.array([])\n",
    "bool_arr = []\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "    print(type(genome.bool_arr))\n",
    "    print(genome.bool_arr)\n",
    "    accuracy = np.append(accuracy, genome.fitness)\n",
    "    # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "    bool_arr.append(genome.bool_arr)\n",
    "\n",
    "bool_arr = np.asarray(bool_arr)\n",
    "\n",
    "print(\" 우성 genome에 대한 Freezing, Trainable Layer 서치 완료 \")\n",
    "print(accuracy.shape)\n",
    "print(bool_arr.shape)\n",
    "\n",
    "# 우성 bool_arr\n",
    "winner_acc = accuracy[:N_BEST]\n",
    "winner_bool_arr = bool_arr[:N_BEST]\n",
    "\n",
    "# CROSSOVER with Sequantial\n",
    "crossover_sequentail(N_CHILDREN, winner_acc, winner_bool_arr, nw_genomes[:N_CHILDREN], 0)\n",
    "crossover_sequentail(N_CHILDREN, winner_acc, winner_bool_arr, nw_genomes[N_CHILDREN:], 0)\n",
    "\n",
    "# mutation\n",
    "mutation(winner_bool_arr, nw_genomes, 0)\n",
    "\n",
    "# 유전 연산 결과를 업데이트하는 과정\n",
    "process_accuracy = np.array([])\n",
    "process_bool_arr = []\n",
    "for i, genome in enumerate(nw_genomes):\n",
    "    print(\"===== Generaton #%s\\tGenome #%s : Fitness %s =====\" % (n_gen, i, genome.fitness))\n",
    "    print(type(genome.bool_arr))\n",
    "    print(genome.bool_arr)\n",
    "    process_accuracy = np.append(process_accuracy, genome.fitness)\n",
    "    # bool_arr = np.append(bool_arr, genome.bool_arr)\n",
    "    process_bool_arr.append(genome.bool_arr)\n",
    "\n",
    "process_bool_arr = np.asarray(process_bool_arr)\n",
    "\n",
    "print(\" 유전연산에 대한 Freezing, Trainable Layer 서치 완료 및 Next Generation 준비 \")\n",
    "print(process_accuracy.shape)\n",
    "print(process_bool_arr.shape)\n",
    "\n",
    "for i, genome in enumerate(genomes):\n",
    "    genome.update_trainable(bool_arr=process_bool_arr[i])\n",
    "    genome.fitness = process_accuracy[i]\n",
    "\n",
    "# genomes.sort(key=lambda x: x.fitness, reverse=True)\n",
    "print('Generation #%s, Done' % (n_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba2a1a9e688c13729bc3ce039aebfba3ed6aba2e3ff21806c4b0dd9559fdc94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
